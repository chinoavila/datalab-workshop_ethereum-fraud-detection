{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvM7IhpVu8H9",
        "outputId": "3472bdf4-4a96-41f5-8445-5b19b17b2bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yBZv9tYvGR0",
        "outputId": "697bf2d8-872c-4047-bb89-ede7321df916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            " AirQualityUCI1.csv\t    go1220031104.fits\n",
            " air_quality_uci2.parquet   hotel_bookings_training.csv\n",
            " air_quality_uci3.parquet   inference_pipeline.joblib\n",
            " AirQualityUCI.csv\t    new_customers.csv\n",
            "'Colab Notebooks'\t    __pycache__\n",
            " correlación.png\t    transaction_dataset_clean.csv\n",
            " Data.csv\t\t    transaction_dataset.csv\n",
            " Funciones.py\t\t    videojuegos.csv\n",
            " go1020011213.fits\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-U25hpxvI73"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing, metrics, model_selection\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import time\n",
        "#from matplotlib import pyplot as plt\n",
        "from matplotlib import pylab as plt\n",
        "from IPython import display\n",
        "\n",
        "# Agregar el directorio de common_functions al path\n",
        "sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'common_functions'))\n",
        "from eval_functions import evaluar, evaluarDerivada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8oIAhDivWdf"
      },
      "source": [
        "Cargamos el dataset limpio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "YPrtb7yXvZwv",
        "outputId": "bc538131-84eb-486f-bcc9-e2fea0e8780f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "numeric_df3"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-99cca305-7fca-4362-8b64-68f8a7964fe3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FLAG</th>\n",
              "      <th>Avg min between sent tnx</th>\n",
              "      <th>Avg min between received tnx</th>\n",
              "      <th>Time Diff between first and last (Mins)</th>\n",
              "      <th>Sent tnx</th>\n",
              "      <th>Received Tnx</th>\n",
              "      <th>Number of Created Contracts</th>\n",
              "      <th>Unique Received From Addresses</th>\n",
              "      <th>Unique Sent To Addresses</th>\n",
              "      <th>min value received</th>\n",
              "      <th>...</th>\n",
              "      <th>ERC20 total Ether sent contract</th>\n",
              "      <th>ERC20 uniq sent addr</th>\n",
              "      <th>ERC20 uniq rec addr</th>\n",
              "      <th>ERC20 uniq sent addr.1</th>\n",
              "      <th>ERC20 uniq rec contract addr</th>\n",
              "      <th>ERC20 min val rec</th>\n",
              "      <th>ERC20 max val rec</th>\n",
              "      <th>ERC20 avg val rec</th>\n",
              "      <th>ERC20 avg val sent</th>\n",
              "      <th>ERC20 uniq sent token name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>844.26</td>\n",
              "      <td>1093.71</td>\n",
              "      <td>704785.63</td>\n",
              "      <td>721</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000e+07</td>\n",
              "      <td>2.655861e+05</td>\n",
              "      <td>2.717799e+05</td>\n",
              "      <td>39.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>12709.07</td>\n",
              "      <td>2958.44</td>\n",
              "      <td>1218216.73</td>\n",
              "      <td>94</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.650000e+02</td>\n",
              "      <td>5.763262e+01</td>\n",
              "      <td>2.260809e+00</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>246194.54</td>\n",
              "      <td>2434.02</td>\n",
              "      <td>516729.30</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.113119</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.428198e+02</td>\n",
              "      <td>6.518901e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>10219.60</td>\n",
              "      <td>15785.09</td>\n",
              "      <td>397555.90</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.141223e+04</td>\n",
              "      <td>1.555550e+03</td>\n",
              "      <td>3.804077e+03</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>36.61</td>\n",
              "      <td>10707.77</td>\n",
              "      <td>382472.42</td>\n",
              "      <td>4598</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000e+04</td>\n",
              "      <td>4.934232e+03</td>\n",
              "      <td>1.372666e+04</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9836</th>\n",
              "      <td>1</td>\n",
              "      <td>12635.10</td>\n",
              "      <td>631.39</td>\n",
              "      <td>58748.48</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>0.004082</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.337000e+00</td>\n",
              "      <td>6.685000e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9837</th>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>1.337000e+01</td>\n",
              "      <td>1.337000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9838</th>\n",
              "      <td>1</td>\n",
              "      <td>2499.44</td>\n",
              "      <td>2189.29</td>\n",
              "      <td>261601.88</td>\n",
              "      <td>67</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>44</td>\n",
              "      <td>0.001078</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000e+03</td>\n",
              "      <td>3.006939e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9839</th>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>110.939207</td>\n",
              "      <td>5.638038</td>\n",
              "      <td>7.598535</td>\n",
              "      <td>0.00344</td>\n",
              "      <td>4.901909</td>\n",
              "      <td>485.614688</td>\n",
              "      <td>1.252524e+08</td>\n",
              "      <td>4.346203e+06</td>\n",
              "      <td>6.318389e+06</td>\n",
              "      <td>1.384931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9840</th>\n",
              "      <td>1</td>\n",
              "      <td>37242.70</td>\n",
              "      <td>149.56</td>\n",
              "      <td>670817.33</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.795233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.018061e+04</td>\n",
              "      <td>1.365244e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9841 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99cca305-7fca-4362-8b64-68f8a7964fe3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99cca305-7fca-4362-8b64-68f8a7964fe3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99cca305-7fca-4362-8b64-68f8a7964fe3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d7aa7a74-7b16-4b41-9a97-36f918407595\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7aa7a74-7b16-4b41-9a97-36f918407595')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d7aa7a74-7b16-4b41-9a97-36f918407595 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a53e58a8-62c9-4603-a30f-5fe9cbfd05c0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('numeric_df3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a53e58a8-62c9-4603-a30f-5fe9cbfd05c0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('numeric_df3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      FLAG  Avg min between sent tnx  Avg min between received tnx  \\\n",
              "0        0                    844.26                       1093.71   \n",
              "1        0                  12709.07                       2958.44   \n",
              "2        0                 246194.54                       2434.02   \n",
              "3        0                  10219.60                      15785.09   \n",
              "4        0                     36.61                      10707.77   \n",
              "...    ...                       ...                           ...   \n",
              "9836     1                  12635.10                        631.39   \n",
              "9837     1                      0.00                          0.00   \n",
              "9838     1                   2499.44                       2189.29   \n",
              "9839     1                      0.00                          0.00   \n",
              "9840     1                  37242.70                        149.56   \n",
              "\n",
              "      Time Diff between first and last (Mins)  Sent tnx  Received Tnx  \\\n",
              "0                                   704785.63       721            89   \n",
              "1                                  1218216.73        94             8   \n",
              "2                                   516729.30         2            10   \n",
              "3                                   397555.90        25             9   \n",
              "4                                   382472.42      4598            20   \n",
              "...                                       ...       ...           ...   \n",
              "9836                                 58748.48         4            13   \n",
              "9837                                     0.00         0             0   \n",
              "9838                                261601.88        67            43   \n",
              "9839                                     0.00         0             1   \n",
              "9840                                670817.33        18             3   \n",
              "\n",
              "      Number of Created Contracts  Unique Received From Addresses  \\\n",
              "0                               0                              40   \n",
              "1                               0                               5   \n",
              "2                               0                              10   \n",
              "3                               0                               7   \n",
              "4                               1                               7   \n",
              "...                           ...                             ...   \n",
              "9836                            0                              11   \n",
              "9837                            0                               0   \n",
              "9838                            0                              31   \n",
              "9839                            0                               1   \n",
              "9840                            0                               1   \n",
              "\n",
              "      Unique Sent To Addresses  min value received  ...  \\\n",
              "0                          118            0.000000  ...   \n",
              "1                           14            0.000000  ...   \n",
              "2                            2            0.113119  ...   \n",
              "3                           13            0.000000  ...   \n",
              "4                           19            0.000000  ...   \n",
              "...                        ...                 ...  ...   \n",
              "9836                         4            0.004082  ...   \n",
              "9837                         0            0.000000  ...   \n",
              "9838                        44            0.001078  ...   \n",
              "9839                         0            0.500000  ...   \n",
              "9840                         5            0.795233  ...   \n",
              "\n",
              "      ERC20 total Ether sent contract  ERC20 uniq sent addr  \\\n",
              "0                            0.000000             30.000000   \n",
              "1                            0.000000              1.000000   \n",
              "2                            0.000000              0.000000   \n",
              "3                            0.000000              2.000000   \n",
              "4                            0.000000              4.000000   \n",
              "...                               ...                   ...   \n",
              "9836                         0.000000              0.000000   \n",
              "9837                         0.000000              0.000000   \n",
              "9838                         0.000000              0.000000   \n",
              "9839                       110.939207              5.638038   \n",
              "9840                         0.000000              0.000000   \n",
              "\n",
              "      ERC20 uniq rec addr  ERC20 uniq sent addr.1  \\\n",
              "0               54.000000                 0.00000   \n",
              "1                5.000000                 0.00000   \n",
              "2                7.000000                 0.00000   \n",
              "3               11.000000                 0.00000   \n",
              "4               23.000000                 0.00000   \n",
              "...                   ...                     ...   \n",
              "9836             2.000000                 0.00000   \n",
              "9837             1.000000                 0.00000   \n",
              "9838             5.000000                 0.00000   \n",
              "9839             7.598535                 0.00344   \n",
              "9840            37.000000                 0.00000   \n",
              "\n",
              "      ERC20 uniq rec contract addr  ERC20 min val rec  ERC20 max val rec  \\\n",
              "0                        58.000000           0.000000       1.500000e+07   \n",
              "1                         7.000000           0.000000       3.650000e+02   \n",
              "2                         8.000000           0.000000       4.428198e+02   \n",
              "3                        11.000000           0.000000       1.141223e+04   \n",
              "4                        27.000000           0.000000       9.000000e+04   \n",
              "...                            ...                ...                ...   \n",
              "9836                      2.000000           0.000000       1.337000e+00   \n",
              "9837                      1.000000          13.370000       1.337000e+01   \n",
              "9838                      5.000000           0.000000       1.500000e+03   \n",
              "9839                      4.901909         485.614688       1.252524e+08   \n",
              "9840                     42.000000           0.000000       2.018061e+04   \n",
              "\n",
              "      ERC20 avg val rec  ERC20 avg val sent  ERC20 uniq sent token name  \n",
              "0          2.655861e+05        2.717799e+05                   39.000000  \n",
              "1          5.763262e+01        2.260809e+00                    1.000000  \n",
              "2          6.518901e+01        0.000000e+00                    0.000000  \n",
              "3          1.555550e+03        3.804077e+03                    1.000000  \n",
              "4          4.934232e+03        1.372666e+04                    6.000000  \n",
              "...                 ...                 ...                         ...  \n",
              "9836       6.685000e-01        0.000000e+00                    0.000000  \n",
              "9837       1.337000e+01        0.000000e+00                    0.000000  \n",
              "9838       3.006939e+02        0.000000e+00                    0.000000  \n",
              "9839       4.346203e+06        6.318389e+06                    1.384931  \n",
              "9840       1.365244e+03        0.000000e+00                    0.000000  \n",
              "\n",
              "[9841 rows x 33 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numeric_df3 = pd.read_csv('/content/drive/MyDrive/transaction_dataset_clean.csv')\n",
        "\n",
        "numeric_df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXHzHJWhxoKO"
      },
      "outputs": [],
      "source": [
        "# Vamos a dividir el dataset entre el valor objetivo (sobre el cual se va a aplicar el SMOTE) y el resto de los atributos\n",
        "\n",
        "X = numeric_df3.drop(\"FLAG\", axis=1)                                   # Quita la columna FLAG del dataset\n",
        "\n",
        "y = numeric_df3[\"FLAG\"]                                                # Extrae la columna FLAG como la variable objetivo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zfjWxzx3GG"
      },
      "source": [
        "Vamos a dvidir en datos de entrenamiento y datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TVeuIJVyBV2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split                   # Se usa para dividir el dataset en conjuntos de entrenamiento y prueba, manteniendo proporciones aleatorias\n",
        "\n",
        "# Dividir en entrenamiento y prueba (sin SMOTE aún)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SSp3xyWyI--"
      },
      "source": [
        "Armamos la estructura de la red neuronal: neuronas de entrada, oculta y salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS64Wt61yQ0m",
        "outputId": "2d7b953a-245b-4564-9326-2269f6ba32a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neuronas de entrada = 32 ; Neuronas de salida = 2\n"
          ]
        }
      ],
      "source": [
        "nFilas = len(X_train)+len(X_test)\n",
        "#nFilas = len(X)\n",
        "entradas = X.shape[1]\n",
        "ocultas = 20\n",
        "\n",
        "# La red tendrá una salida para cada tipo de fraude (fraude o no fraude)\n",
        "salidas = len(np.unique(y))\n",
        "print(\"Neuronas de entrada = %d ; Neuronas de salida = %d\" % (entradas, salidas))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IoUHIwxyaQG"
      },
      "source": [
        "Normalizamos los datos utilizando la media y desvío."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoC7O_3QyeCu",
        "outputId": "d7c6a4ae-703a-47e6-ef92-d9cb8306cca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8460    1\n",
            "6081    0\n",
            "8966    1\n",
            "1535    0\n",
            "7304    0\n",
            "       ..\n",
            "5734    0\n",
            "5191    0\n",
            "5390    0\n",
            "860     0\n",
            "7270    0\n",
            "Name: FLAG, Length: 6888, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "normalizarEntrada = 1  # 1 si normaliza; 0 si no\n",
        "\n",
        "if normalizarEntrada:\n",
        "    # Escala los valores restando la media y diviendiendo entre el desvió estandar\n",
        "    standard_scaler = preprocessing.StandardScaler()\n",
        "    X_train = standard_scaler.fit_transform(X_train)\n",
        "    X_test = standard_scaler.transform(X_test)\n",
        "\n",
        "y_trainB = np.zeros((len(y_train), salidas))                            # Armamos una matriz de zeros, en la cual van a ir 0 y 1, donde el 1 irá en la\n",
        "for o in range(len(y_train)):                                           # posición de la clase, ej, si es tipo 1 ==> la fila será [0, 1], si es tipo 0\n",
        "    y_trainB[o, y_train.iloc[o]]=1                                           # la fila será [1, 0], y así\n",
        "\n",
        "print(y_train)\n",
        "y_trainB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX4KXJGfyp7e"
      },
      "source": [
        "Armamos las matrices de pesos y bias tanto para la capa de entrada a la oculta como para la capa oculta a la salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgXTD6xyyrCm",
        "outputId": "2900d6b8-3e74-4a73-cf43-762556131e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Como tengo 32 neuronas de entrada, 20 ocultas y 2 de salida, para la primera parte de la red voy a tener 640 arcos y para la segunda 40, haciendo un total de 680 arcos para la red\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 5.42106980e-01, -6.16886004e-01,  9.45685270e-01,\n",
              "        -3.29205199e-01, -7.76930692e-01,  7.98421856e-02,\n",
              "         2.41571872e-01,  6.67172912e-01, -5.02010531e-01,\n",
              "         8.33338483e-01, -9.26855694e-03, -1.73898858e-01,\n",
              "        -4.45220044e-01, -2.29791134e-01, -6.14861162e-01,\n",
              "         9.69019228e-01,  3.27911682e-01,  9.60704729e-01,\n",
              "        -7.54540744e-01,  5.95781416e-01,  6.83592671e-01,\n",
              "         1.15342283e-01, -2.91520128e-03, -5.91879584e-01,\n",
              "         5.00213012e-01,  7.64224160e-01,  1.92721796e-01,\n",
              "        -1.00780435e-02, -9.66801437e-01,  2.66308674e-01,\n",
              "        -1.42632605e-01, -2.86392459e-01],\n",
              "       [-7.00901283e-01,  3.15967953e-01, -9.80162102e-01,\n",
              "        -6.16572128e-01, -2.38521525e-02,  4.23035319e-01,\n",
              "        -3.32294515e-01, -4.98689007e-01,  6.00654688e-01,\n",
              "        -3.99037178e-01,  6.69641306e-01, -1.73751827e-01,\n",
              "         3.19575667e-01,  6.52255943e-01, -5.03506607e-01,\n",
              "         1.15330873e-01, -8.28020204e-01, -3.50710592e-02,\n",
              "         9.55258921e-01, -3.74310944e-01,  4.93791391e-01,\n",
              "        -1.73095042e-01,  4.34848986e-01,  9.68983189e-01,\n",
              "        -7.15735201e-01,  5.41873016e-01,  1.25553885e-01,\n",
              "        -4.71920426e-01,  7.31175868e-01, -2.49718138e-01,\n",
              "         6.09366666e-01, -7.40164036e-01],\n",
              "       [-8.52863250e-01, -4.66534044e-01, -7.55214072e-01,\n",
              "         2.10628506e-01, -9.53268187e-01, -5.19966877e-01,\n",
              "         3.31233490e-01,  7.41268053e-01, -8.71481646e-01,\n",
              "        -5.88494908e-02, -1.23217754e-02,  1.59278198e-01,\n",
              "         7.97963698e-01, -2.32782518e-01, -2.16457750e-01,\n",
              "        -5.42243049e-01,  3.78976384e-01,  9.09665016e-01,\n",
              "        -9.98947633e-01, -3.43861358e-01, -9.96056529e-02,\n",
              "         7.45727516e-01, -2.69778367e-01, -8.79295356e-01,\n",
              "         1.95211402e-02,  5.89172611e-01,  5.18916899e-01,\n",
              "        -7.38874005e-01,  2.81417931e-01,  3.91142182e-01,\n",
              "        -1.70826820e-01,  9.77820954e-01],\n",
              "       [ 9.05123200e-01, -7.26249582e-01,  2.19579851e-01,\n",
              "         4.43899525e-01, -8.44084665e-01,  7.53265748e-02,\n",
              "        -8.58715980e-03, -1.16143146e-01, -5.98393565e-01,\n",
              "        -7.43824478e-01, -3.36065724e-01, -2.70183609e-01,\n",
              "         3.71909829e-01,  2.65395370e-01, -1.80703561e-01,\n",
              "         5.46146565e-01,  1.34337686e-01,  2.88835875e-01,\n",
              "         8.73647656e-01,  2.90213487e-01, -9.29827835e-01,\n",
              "        -1.32092670e-01, -8.08100593e-01, -3.98085656e-01,\n",
              "         1.94593695e-01,  4.94684051e-01,  4.27504983e-01,\n",
              "        -5.44191095e-01, -1.21879097e-01, -1.97389143e-01,\n",
              "        -9.63931485e-01, -4.39638349e-02],\n",
              "       [-1.58888082e-01,  8.22088895e-01,  3.43049605e-01,\n",
              "        -4.87935079e-01,  6.00383929e-01, -7.91873827e-01,\n",
              "         6.55414910e-02,  4.75057427e-01, -8.38992256e-01,\n",
              "        -5.27867401e-01,  2.71365941e-01, -4.74662179e-02,\n",
              "         8.48485344e-01, -7.31121714e-01,  8.58875256e-01,\n",
              "         3.86222412e-01, -5.04824380e-01, -2.49920039e-01,\n",
              "        -5.41868454e-02, -8.32037401e-01,  6.91358473e-01,\n",
              "         7.60376310e-02,  3.07151208e-01,  2.69950884e-01,\n",
              "         5.58128284e-01,  3.37879246e-01, -8.09609602e-01,\n",
              "         8.43229672e-01,  7.55928680e-02, -7.00461826e-01,\n",
              "        -1.51624809e-01, -5.38992782e-01],\n",
              "       [ 9.33106672e-01, -7.72017573e-01,  8.63271946e-01,\n",
              "        -4.16992732e-01, -1.51886416e-01, -8.10398930e-02,\n",
              "        -2.47451597e-01, -5.91785325e-01, -5.61728704e-01,\n",
              "         8.52758398e-01,  1.37016323e-01,  7.45432082e-01,\n",
              "         8.54567732e-01,  5.51189076e-02,  3.33192151e-01,\n",
              "        -3.54283223e-02,  4.95179523e-03, -7.24256867e-01,\n",
              "        -3.68223244e-01,  6.01105558e-01,  1.52254307e-01,\n",
              "        -1.79103306e-01,  7.28004014e-01, -3.34604641e-01,\n",
              "         9.74232676e-01,  9.81067080e-01,  3.04064192e-01,\n",
              "        -2.67405634e-01,  5.21516651e-01,  3.17820341e-01,\n",
              "         6.54972757e-01,  1.49654370e-01],\n",
              "       [ 4.91446841e-01, -2.47771268e-01, -8.29338330e-01,\n",
              "        -2.41066725e-01,  6.87344213e-01,  5.09359880e-01,\n",
              "         6.44836139e-02, -4.69106492e-01, -1.53295289e-01,\n",
              "        -9.29776956e-01,  4.75736330e-02,  5.49646366e-01,\n",
              "        -6.04850457e-01, -8.60911945e-01,  5.97849898e-01,\n",
              "        -8.81065907e-01,  1.14572445e-01,  8.06372126e-01,\n",
              "        -7.47288957e-01,  5.80275971e-01,  2.24954151e-01,\n",
              "         8.60366255e-01,  5.07565530e-01,  9.44450622e-01,\n",
              "        -8.28778407e-02,  6.08486859e-01, -9.83961438e-01,\n",
              "         3.31865302e-02,  6.86752355e-01,  3.51026611e-01,\n",
              "        -2.88691659e-01,  4.36046275e-01],\n",
              "       [ 6.42662113e-01, -4.18834483e-01, -9.54745539e-01,\n",
              "         3.85885123e-04, -1.55529860e-01, -5.19486416e-01,\n",
              "        -3.79351265e-01,  2.69347316e-01, -9.48892972e-01,\n",
              "        -8.00260605e-01, -5.25166303e-01,  3.96281957e-01,\n",
              "        -6.58780416e-01,  1.35519331e-01,  6.95813842e-01,\n",
              "         3.12181306e-01, -7.03523977e-01, -4.10903960e-01,\n",
              "         3.94607631e-01, -3.82894081e-01, -7.70591870e-01,\n",
              "         2.51963582e-01, -5.11646724e-01,  8.55696225e-01,\n",
              "         1.78600321e-02,  1.66718604e-01,  6.30233041e-01,\n",
              "        -5.39877781e-01, -7.88960617e-01, -6.82083508e-01,\n",
              "        -7.33385057e-01,  8.92422750e-01],\n",
              "       [-8.12319340e-01, -8.75755263e-01, -5.00401884e-02,\n",
              "         3.38360888e-01,  8.07335374e-01,  9.87550888e-01,\n",
              "        -5.10270485e-01,  2.08876745e-02,  8.79676210e-01,\n",
              "         6.00597583e-01, -5.12629125e-02,  1.64301386e-01,\n",
              "         1.45466877e-01, -2.19036504e-01,  9.07130274e-01,\n",
              "        -3.51983178e-01, -5.68999043e-01,  3.16491354e-01,\n",
              "        -5.95828440e-02,  5.30209520e-01,  7.07410830e-01,\n",
              "        -1.19960435e-01,  7.30895653e-01, -1.04497787e-01,\n",
              "        -6.17447401e-01,  6.38290894e-01,  1.00318512e-01,\n",
              "        -1.98157668e-01,  3.39862262e-01,  6.57745815e-01,\n",
              "         1.23353725e-01,  4.55495872e-01],\n",
              "       [-2.48000936e-01,  7.35492164e-01, -4.24836170e-01,\n",
              "        -5.02335454e-01, -4.90460542e-01,  8.46215438e-01,\n",
              "         9.23344658e-01, -8.47110747e-01,  9.74203402e-01,\n",
              "        -2.17165738e-01,  5.83086434e-01,  5.53160634e-01,\n",
              "         8.78284766e-01, -5.43732742e-01, -3.05503853e-01,\n",
              "         5.33784628e-01,  6.14183427e-01, -9.23171537e-01,\n",
              "        -2.29086976e-01, -4.52845623e-02,  8.91356011e-01,\n",
              "         8.25507130e-01,  1.47483018e-01,  7.38036121e-01,\n",
              "         7.16348122e-01, -9.69472893e-01,  9.97060514e-01,\n",
              "        -5.21956139e-01,  3.70062438e-01, -9.47262094e-01,\n",
              "         5.25795466e-01,  6.46146518e-02],\n",
              "       [ 5.08921559e-01, -8.51732173e-01, -9.94653422e-01,\n",
              "         5.02840537e-01, -4.23547863e-01,  2.11154383e-01,\n",
              "        -8.79341988e-01, -4.18994847e-02, -3.84861716e-01,\n",
              "         4.99384341e-01, -9.97759461e-01, -2.67448135e-02,\n",
              "        -3.49236879e-01, -6.90958742e-01, -7.94149201e-01,\n",
              "        -5.84876635e-01,  3.76251303e-01, -1.47273303e-02,\n",
              "         3.52123075e-01, -9.05982897e-01, -4.72531860e-01,\n",
              "         8.61081308e-01,  6.12070635e-02,  4.79329272e-03,\n",
              "        -3.89048837e-01, -7.12837370e-01, -8.94576770e-01,\n",
              "        -2.61330055e-01, -3.81815586e-01,  3.72224806e-01,\n",
              "         2.97480602e-01, -4.34204612e-01],\n",
              "       [ 2.48830890e-02, -4.93226784e-01, -6.55676762e-01,\n",
              "         1.87270892e-01,  8.00263155e-01,  6.42149993e-01,\n",
              "        -2.64441212e-02,  7.24749984e-03, -5.56114607e-01,\n",
              "        -2.62338448e-01, -8.35175570e-01, -2.79901809e-01,\n",
              "        -7.80826470e-01,  1.69071722e-01,  6.93462434e-01,\n",
              "         4.86643235e-01, -5.77219489e-01,  3.24592347e-02,\n",
              "         3.69962580e-02, -1.27564215e-01, -8.68567767e-01,\n",
              "         9.43832125e-01,  4.70630092e-01, -9.44032028e-01,\n",
              "         3.47992911e-01,  5.33413869e-01,  9.18911254e-01,\n",
              "         9.55695645e-01,  1.11773723e-01, -3.37133119e-01,\n",
              "         1.68835117e-01,  3.45027525e-01],\n",
              "       [ 7.47596720e-02,  3.46481796e-01,  5.53261297e-01,\n",
              "         8.90370191e-01, -2.58428052e-01,  3.87056411e-01,\n",
              "        -9.36899694e-01, -2.69462441e-01,  6.74497858e-01,\n",
              "        -2.31966239e-02, -6.13255853e-01, -3.75706667e-01,\n",
              "         7.80728639e-02,  8.41018684e-01,  9.84097622e-01,\n",
              "        -2.48160658e-01, -9.57738006e-01,  2.73010972e-01,\n",
              "         9.23593273e-01, -8.09053080e-01, -6.33108420e-01,\n",
              "        -9.96099013e-01,  9.48613445e-01,  9.47043713e-02,\n",
              "         3.84813388e-01,  7.42461833e-02, -9.94753816e-01,\n",
              "        -3.31036704e-01,  8.06751142e-01, -1.95401260e-01,\n",
              "        -2.07747900e-01,  8.09398409e-01],\n",
              "       [ 8.37944443e-01, -5.74090856e-01, -5.55666686e-01,\n",
              "        -2.33568083e-01, -3.34767465e-02,  2.40645188e-01,\n",
              "         9.24122563e-01,  9.56182923e-01, -9.52642513e-01,\n",
              "         5.76868794e-01, -3.18440797e-01,  9.02484684e-01,\n",
              "        -3.90296385e-01, -5.71161409e-01, -8.23911668e-01,\n",
              "         1.79604180e-01,  6.31375179e-01,  1.27754614e-02,\n",
              "         8.37366299e-01, -1.91462603e-02,  7.47578500e-01,\n",
              "        -5.42229174e-01,  3.09887086e-01,  9.67371737e-01,\n",
              "         1.67087668e-01,  8.75289276e-01,  5.66211238e-01,\n",
              "        -3.64918453e-01,  2.18114310e-01,  4.48834602e-01,\n",
              "        -8.59383544e-01,  2.16208152e-01],\n",
              "       [-3.89216376e-02,  1.68305463e-01, -3.91530540e-01,\n",
              "        -3.66101010e-01,  8.50884642e-01, -5.46989259e-01,\n",
              "         5.05346390e-01,  2.76685825e-01, -9.60150967e-01,\n",
              "        -1.15449948e-01, -1.21990540e-01, -3.73415254e-01,\n",
              "         5.78894718e-01,  9.01188360e-01,  4.53077712e-01,\n",
              "         6.03400488e-01,  3.93402706e-01,  2.70294813e-01,\n",
              "         2.08961733e-01, -2.44810733e-01, -7.76093558e-01,\n",
              "        -1.31160977e-01, -7.20440371e-01, -1.58219544e-01,\n",
              "         9.89436388e-01, -9.75095446e-01,  9.27448114e-01,\n",
              "         2.19014605e-01, -6.16056328e-01, -5.74698259e-01,\n",
              "        -1.67142615e-01,  4.29626341e-01],\n",
              "       [-8.98043118e-02, -5.90587063e-01,  9.76530260e-01,\n",
              "         7.49174404e-01,  3.46902800e-01,  9.01334404e-01,\n",
              "         8.96853058e-02,  2.06299841e-01,  7.97259860e-01,\n",
              "        -1.65345328e-01,  9.87864733e-01,  2.59355687e-01,\n",
              "         4.10264251e-01,  4.77714390e-01,  3.50418684e-01,\n",
              "        -6.85535747e-01,  1.82161892e-01, -2.22561875e-01,\n",
              "         6.31426660e-04,  9.59334209e-01, -8.03123149e-01,\n",
              "         5.96216551e-01, -2.58548498e-01, -3.58496058e-02,\n",
              "        -4.65595242e-01,  5.33841868e-01,  3.00762076e-01,\n",
              "        -8.67293343e-01, -3.33714870e-01, -8.87085765e-01,\n",
              "         6.08831549e-01,  1.03838830e-02],\n",
              "       [-4.60891534e-01, -8.71397920e-01,  8.12681388e-01,\n",
              "         3.08041979e-02, -5.92466506e-01,  8.44903417e-01,\n",
              "        -3.01864306e-01, -1.97918907e-01, -6.33586779e-01,\n",
              "         9.15035831e-01, -3.08776225e-01, -4.21327060e-01,\n",
              "         9.67499791e-01, -6.49669775e-02, -4.95191452e-01,\n",
              "        -1.58318728e-01, -4.02452079e-01,  7.57261155e-01,\n",
              "         3.57857624e-01,  9.61016238e-01, -7.05694293e-02,\n",
              "        -8.10742003e-01,  4.47313716e-01, -5.37210582e-02,\n",
              "         7.80220421e-01, -5.37988288e-01,  2.11047155e-01,\n",
              "        -2.95764131e-01,  6.05451392e-01,  5.95061533e-01,\n",
              "        -9.53224628e-01,  5.42939820e-01],\n",
              "       [ 3.20227124e-01, -6.26350931e-01,  6.75272654e-02,\n",
              "         8.40348641e-01,  2.75296510e-01,  8.15522091e-01,\n",
              "        -6.38349326e-01, -2.33002131e-01,  7.06739165e-01,\n",
              "         8.94180253e-01, -5.23291030e-01, -7.02267266e-01,\n",
              "        -3.58124077e-01, -1.36521345e-01, -5.58941834e-01,\n",
              "         8.55265026e-01,  3.97198535e-02, -8.86584945e-01,\n",
              "         6.64885158e-02, -3.05407127e-01,  5.74597582e-01,\n",
              "        -4.31471995e-01, -5.89831111e-01,  3.57293949e-01,\n",
              "        -1.30014324e-01,  5.21270917e-01,  1.84022935e-01,\n",
              "        -8.63583469e-02, -6.88388703e-01,  4.50189444e-01,\n",
              "        -5.54025693e-01, -1.23132867e-01],\n",
              "       [-3.20013933e-01, -8.83781551e-02, -2.76120474e-02,\n",
              "         5.39037281e-01, -9.66299445e-01, -8.45284882e-01,\n",
              "        -6.98554987e-01, -1.24706216e-02, -2.22648365e-01,\n",
              "         6.20721935e-01,  1.01572812e-01, -7.74500979e-01,\n",
              "         9.24893732e-01, -5.62663030e-01, -7.98035910e-01,\n",
              "         8.68141580e-01, -3.21776812e-01,  6.54587676e-01,\n",
              "         1.69501897e-01, -9.37633935e-02, -8.45154895e-01,\n",
              "         3.48693858e-01,  1.51753986e-01, -5.11688870e-01,\n",
              "         4.03958867e-01, -7.64994907e-02, -9.97658073e-01,\n",
              "         5.81200759e-01, -7.91371434e-01, -3.85677341e-01,\n",
              "        -2.22595732e-01,  5.52969907e-01],\n",
              "       [ 5.85514372e-02, -7.49628501e-01, -9.42810107e-01,\n",
              "        -5.89405223e-01, -8.63059705e-01,  9.38274490e-01,\n",
              "        -2.69007119e-01,  7.07576270e-02, -3.30197649e-01,\n",
              "        -2.92159983e-01,  6.94862446e-01,  1.35457398e-01,\n",
              "        -7.02823913e-01,  2.92944357e-01,  2.40373125e-01,\n",
              "        -6.90961559e-01,  9.52916590e-01, -8.98345679e-01,\n",
              "        -4.79928475e-01, -7.43983202e-01,  5.44843176e-02,\n",
              "         2.29543104e-01,  2.81644858e-01,  1.64007205e-01,\n",
              "         6.56664090e-01,  6.92099522e-01, -5.23047616e-01,\n",
              "         2.07926079e-01,  8.61944098e-01,  6.50070932e-01,\n",
              "         8.72187731e-01,  5.42741776e-01]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Elijo las matrices de pesos y bias que van de la entrada a la capa oculta (w1 y b1) y los que van de la oculta a la salida (w2 y b2)\n",
        "\n",
        "W1 = np.random.uniform(-1,1,[ocultas, entradas])                      # Elijo números aleatorios entre -1 y 1, y me queda una matriz de 20x38 (oculta, entrada)\n",
        "b1 = np.random.uniform(-1,1, [ocultas,1])\n",
        "W2 = np.random.uniform(-1,1,[salidas, ocultas])\n",
        "b2 = np.random.uniform(-1,1, [salidas,1])\n",
        "\n",
        "#dibuPtos_y_2Rectas(X,Y, W1, b1)\n",
        "\n",
        "print(f\"Como tengo {entradas} neuronas de entrada, {ocultas} ocultas y {salidas} de salida, para la primera parte de la red voy a tener {entradas*ocultas} arcos y para la segunda {ocultas*salidas}, haciendo un total de {entradas*ocultas+ocultas*salidas} arcos para la red\")\n",
        "W1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDzh97iZy6XW"
      },
      "source": [
        "Definimos las funciones de activación. Las cuales son sumamente importante para poder encontrar relaciones o patrones no lineales entre los atributos del dataset, es decir permite introducir no linealidad en el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaiqnD9xy7UO"
      },
      "outputs": [],
      "source": [
        "FunH = 'sigmoid'\n",
        "FunO = 'tanh'\n",
        "\n",
        "if (FunO=='tanh'):\n",
        "    y_trainB = 2*y_trainB -1                            # Transforma los valores de salida de one-hot encoding de [0, 1] a [-1, 1]. Esto es importante si la\n",
        "                                                        # función de activación de salida es tanh, porque tanh(x) siempre da valores en el rango (-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imQiVOw-zHhO"
      },
      "source": [
        "Ciclo de entrenamiento de la red neuronal feedforward usando backpropagation con descenso del gradiente. Caractéristicas de la red:\n",
        "\n",
        "Activaciones 'sigmoid' y 'tanh'\n",
        "\n",
        "Aprendizaje estocástico\n",
        "\n",
        "Criterio de parada basado en convergencia del error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qUKsjwCzIdW",
        "outputId": "2413a16f-e85f-4ee5-b6f1-0ada0538819d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Funciones.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  return (1.0/(1+np.exp(np.dot(-1,x))))\n"
          ]
        }
      ],
      "source": [
        "nFilas = X_train.shape[0]                                                  # Cantidad de ejemplos de entrenamiento\n",
        "\n",
        "alfa = 0.1                                                                 # Tasa de aprendizaje (learning rate)\n",
        "CotaError = 1.0e-4                                                         # Umbral mínimo de error para detener\n",
        "MAX_ITERA = 400                                                            # Máx. cantidad de iteraciones permitidas\n",
        "ite = 0                                                                    # Contador de iteraciones\n",
        "errorAnt = 0                                                               # Error de la iteración anterior\n",
        "AVGError = 1                                                               # Error promedio inicial (alto)\n",
        "errores = []                                                               # Lista para guardar la evolución del error\n",
        "ph=0\n",
        "while ( abs(AVGError-errorAnt) > CotaError ) and ( ite < MAX_ITERA ):               # Repite el entrenamiento hasta que el cambio en el error promedio es pequeño (converge) o se alcanza el límite de iteraciones.\n",
        "    errorAnt = AVGError\n",
        "    AVGError = 0\n",
        "    for e in range(nFilas):  # para cada ejemplo, es decir, se actualiza la red ejemplo por ejemplo\n",
        "\n",
        "        xi = X_train[e:e+1, :]      # ejemplo a ingresar a la red\n",
        "        yi = y_trainB[e:e+1, :]     # salida esperada para el ejemplo seleccionado\n",
        "\n",
        "        # propagar el ejemplo hacia adelante\n",
        "        netasH = W1 @ xi.T + b1                  # Entrada a la capa oculta\n",
        "        salidasH = evaluar(FunH, netasH)         # Salida de la capa oculta\n",
        "        netasO = W2 @ salidasH + b2              # Entrada a la capa de salida\n",
        "        salidasO = evaluar(FunO, netasO)         # Salida de la red\n",
        "\n",
        "        # calcular los errores en ambas capas\n",
        "        ErrorSalida = yi.T-salidasO                  # Diferencia entre la salida deseada (yi) y la salida real\n",
        "\n",
        "\n",
        "        # Calcular los deltas o gradientes locales de error para cada capa, usando la derivada de la función de activación. Es la parte clave del algoritmo de backpropagation\n",
        "        deltaO = ErrorSalida * evaluarDerivada(FunO,salidasO)\n",
        "        deltaH = evaluarDerivada(FunH,salidasH)*(W2.T @ deltaO)\n",
        "\n",
        "        # corregir todos los pesos según los deltas calculados\n",
        "        W1 = W1 + alfa * deltaH @ xi\n",
        "        b1 = b1 + alfa * deltaH\n",
        "        W2 = W2 + alfa * deltaO @ salidasH.T\n",
        "        b2 = b2 + alfa * deltaO\n",
        "\n",
        "        AVGError = AVGError + np.mean(ErrorSalida**2)           # Se va acumulando el error cuadrático medio por ejemplo\n",
        "\n",
        "    # Se promedia el error total y se guarda para graficar o monitorear la evolución\n",
        "    AVGError = AVGError / nFilas\n",
        "    errores.append(AVGError)\n",
        "\n",
        "    ite = ite + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q_It7_-zPM-"
      },
      "source": [
        "Gráfico del error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "8frnwdy9zQ0e",
        "outputId": "bd9c8da2-72d5-4a74-f56d-878522d2e274"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.11994628832473933\n"
          ]
        }
      ],
      "source": [
        "plt.plot(range(1, len(errores) + 1), errores, marker='o')      # En el eje x va el n° de iteraciones, lo hacemos tomando un rango desde 1 hasta la long de errores (el +1 es porque range no toma el límete superior)\n",
        "plt.xlabel('Iteraciones')\n",
        "plt.ylabel('ECM')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(min(errores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A6-PHLJzcB2",
        "outputId": "c31f5158-3abd-4313-d1b2-d7eadee8d0e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.9804788 ,  0.90693768, -0.9716321 ,  1.        ,  0.99511217],\n",
              "       [ 0.98057329, -0.91367791,  0.96758949, -1.        , -0.99504014]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Respuesta de la red para los datos de ENTRENAMIENTO, es decir, los pesos y bias óptimos para el entrenamiento de acuero a lo que aprendió la red\n",
        "\n",
        "NetasH = W1 @ X_train.T + b1                          # Calcula las entradas netas de las neuronas ocultas.\n",
        "SalidasH = evaluar(FunH, NetasH)                      # salidas de la capa oculta.\n",
        "NetasO = W2 @ SalidasH + b2                           # Calcula las entradas netas de las neuronas de salida.\n",
        "SalidasO = evaluar(FunO, NetasO)                      # salidas de la capa de salida.\n",
        "\n",
        "SalidasO[:, :5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEHlO2b9zghl"
      },
      "source": [
        "Porcentaje de aciertos del entrenamineto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPucUQaMzhsG",
        "outputId": "77efc3d0-6e61-43e0-8921-8ce11b5c88f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "% aciertos X_train : 0.967\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(SalidasO,axis=0)\n",
        "print(\"%% aciertos X_train : %.3f\" % metrics.accuracy_score(y_train,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW4E11HDznMW"
      },
      "source": [
        "Generemos un informe completo de métricas de clasificación usando las verdaderas (y_train) y las predichas (y_pred) clases.\n",
        "\n",
        "Este informe incluye para cada clase:\n",
        "\n",
        "precision: qué proporción de las predicciones para esa clase fueron correctas.\n",
        "\n",
        "recall (sensibilidad): qué proporción de los verdaderos ejemplos de esa clase fueron bien clasificados.\n",
        "\n",
        "f1-score: el promedio armónico de precisión y recall.\n",
        "\n",
        "support: cuántos ejemplos reales había de esa clase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4HD_JNLzoHm",
        "outputId": "eccc262d-8ed2-4f6a-8cfe-3ce083fff4ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Informe de métricas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      5359\n",
            "           1       0.93      0.93      0.93      1529\n",
            "\n",
            "    accuracy                           0.97      6888\n",
            "   macro avg       0.95      0.95      0.95      6888\n",
            "weighted avg       0.97      0.97      0.97      6888\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = metrics.classification_report(y_train,y_pred)\n",
        "print(\"Informe de métricas:\\n%s\" % report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXoYm3nk0O-1",
        "outputId": "432cf444-8643-4305-9491-663516a03057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[5244  115]\n",
            " [ 110 1419]]\n",
            "\n",
            "Aciertos y errores por clase:\n",
            "Clase 0: Aciertos = 5244, Errores = 115\n",
            "Clase 1: Aciertos = 1419, Errores = 110\n"
          ]
        }
      ],
      "source": [
        "MM = metrics.confusion_matrix(y_train,y_pred)\n",
        "print(\"Confusion matrix:\\n%s\" % MM)\n",
        "\n",
        "# Calcular e imprimir aciertos y errores por clase\n",
        "print(\"\\nAciertos y errores por clase:\")\n",
        "num_clases = MM.shape[0]\n",
        "\n",
        "for i in range(num_clases):\n",
        "    aciertos = MM[i, i]\n",
        "    errores = sum(MM[i, :]) - aciertos\n",
        "    print(f\"Clase {i}: Aciertos = {aciertos}, Errores = {errores}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBycKSo80VE-",
        "outputId": "9f69c9a4-1284-4400-fc65-b9dbc506c705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "% aciertos X_test : 0.957\n",
            "\n",
            "Confusion matrix Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      2303\n",
            "           1       0.91      0.90      0.90       650\n",
            "\n",
            "    accuracy                           0.96      2953\n",
            "   macro avg       0.94      0.94      0.94      2953\n",
            "weighted avg       0.96      0.96      0.96      2953\n",
            "\n",
            "Confusion matrix:\n",
            "[[2243   60]\n",
            " [  66  584]]\n",
            "\n",
            "------Si usamos la normalización lineal, el acierto es de 0.9573315272604132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Funciones.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  return (1.0/(1+np.exp(np.dot(-1,x))))\n"
          ]
        }
      ],
      "source": [
        "# -- TESTING ---\n",
        "NetasH = W1 @ X_test.T + b1\n",
        "SalidasH = evaluar(FunH, NetasH)\n",
        "NetasO = W2 @ SalidasH + b2\n",
        "SalidasO = evaluar(FunO, NetasO)\n",
        "\n",
        "y_pred = np.argmax(SalidasO,axis=0)\n",
        "print(\"%% aciertos X_test : %.3f\\n\" % metrics.accuracy_score(y_test,y_pred))\n",
        "\n",
        "report = metrics.classification_report((y_test),(y_pred))\n",
        "print(\"Confusion matrix Test:\\n%s\" % report)\n",
        "\n",
        "MM = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\\n%s\" % MM)\n",
        "\n",
        "print('\\n------Si usamos la normalización lineal, el acierto es de',metrics.accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKTNWMig0ogl"
      },
      "source": [
        "**Características sin el oversampling**\n",
        "\n",
        "La diferencia entre el accuracy de entrenamiento (0.966) y prueba (0.957) es muy pequeña. Esto indica que el modelo NO está sobreajustado (overfitting) NI subajustado (underfitting). En otras palabras, el modelo generaliza bien a datos nuevos.\n",
        "\n",
        "Un accuracy del 95.7% en datos de prueba sugiere que el modelo hace predicciones correctas para una gran mayoría de los casos. Esto es un indicador de que el modelo tiene un buen desempeño global."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2CCTnFx03-N"
      },
      "source": [
        "**1) Métricas clave para cada clase**\n",
        "\n",
        "**Clase 0 (no fraude):**\n",
        "\n",
        "**-Precision:** 0.97, El 97% de los registros que el modelo predijo como \"no fraude\" fueron correctos.\n",
        "\n",
        "**-Recall:** 0.97, El modelo detectó el 97% de todos los registros reales de \"no fraude\".\n",
        "\n",
        "**-F1-Score:** 0.97, Excelente balance entre precisión y recall en esta clase.\n",
        "\n",
        "**Clase 1 (fraude):**\n",
        "\n",
        "**-Precisión:** 0.91, El 91% de los registros predichos como \"fraude\" son correctos.\n",
        "\n",
        "**-Recall:** 0.90, El modelo detectó el 90% de los fraudes reales.\n",
        "\n",
        "**-F1-Score:** 0.90, Buen balance entre precisión y recall, especialmente considerando que detectar fraudes es la prioridad.\n",
        "\n",
        "**2) Evaluación general del modelo**\n",
        "\n",
        "**-Accuracy:** 0.96, El modelo clasifica correctamente el 96% de los casos totales. Esto es muy bueno, pero en datasets desbalanceados el accuracy puede ser engañoso.\n",
        "\n",
        "**-Macro avg (media de las métricas para ambas clases, sin considerar el tamaño de cada clase):** - Precision: 0.94 Recall: 0.94 F1-Score: 0.94. Buen desempeño para ambas clases.\n",
        "\n",
        "**-Weighted avg (media ponderada según el tamaño de cada clase):** Precision: 0.96 Recall: 0.96 F1-Score: 0.96. Este valor refleja el desempeño general del modelo, considerando que la clase mayoritaria (no fraude) domina.\n",
        "\n",
        "**3) Análisis y observaciones**\n",
        "\n",
        "**-detectando fraudes (clase 1):** Recall de 0.90: El modelo identifica la mayoría de los fraudes, lo que es crucial en este problema. Sin embargo, el 10% de los fraudes no fueron detectados. Dependiendo del contexto, esto podría ser un área de mejora si se busca minimizar falsos negativos (fraudes no detectados).\n",
        "\n",
        "**-Precisión en fraudes (Clase 1):** Precision de 0.91: Esto significa que el modelo mantiene un buen control sobre los falsos positivos (casos que clasifica como fraude pero no lo son)\n",
        "\n",
        "**- Calse 0 (no fraude)** El modelo tiene excelente desempeño en no fraudes, lo cual es esperado dado que hay más datos representativos de esta clase.\n",
        "\n",
        "**- Balance entre clases** El macro avg (0.94 en F1-Score) sugiere que el modelo trata bien ambas clases, pero un recall más alto para fraudes podría mejorarse.\n",
        "\n",
        "**4) Conclusiones** Definitivamente es un buen clasificador, pero se lo puede mejorar, y más aún si se quiere detectar la mayor cantidad de fraudes, habría que aumentar el recall de la clase 1 y que sea más parejo al resto de las métricas o incluso al mismo recall de la clase 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCm_3DoG2_a8"
      },
      "source": [
        "**Características con oversampling**\n",
        "\n",
        "Se aplicó la SMOTE después de la división de los datos, cosa que solo se aplique sobre los datos de entrenamiento. El dataset quedó un 60/40.\n",
        "\n",
        "Los accuracy rondan entre el 45 y 60%, un modelo bastante malo. Todas las métricas están en el orden del accuracy, sin embargo el recall de la clase 1 (fraude) es 0.99, prácticamente lo único positivo del oversampling.\n",
        "\n",
        "la precision y el accuracy general se deterioran porque el modelo clasifica demasiados casos como fraude, generando más falsos positivos.\n",
        "\n",
        "Quizás la causa se deba a que la distribución real de la clase minoritaria (clase 1, fraude) es irregular o tiene patrones únicos, por lo que los datos sintéticos podrían no representar adecuadamente esta clase, lo que afecta la capacidad del modelo de generalizar bien en el conjunto de prueba."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
