# üßæ Resumen

El proyecto comenz√≥ con el an√°lisis de un conjunto de datos de transacciones en Ethereum, el cual presentaba un fuerte desbalance entre transacciones leg√≠timas y fraudulentas. Se llev√≥ a cabo un an√°lisis exploratorio de datos (EDA) y una limpieza del dataset, evaluando diferentes estrategias de balanceo como SMOTE. A partir de esta base, se entrenaron y compararon una serie de modelos: una red neuronal implementada desde cero, una red utilizando la librer√≠a Keras, un modelo cl√°sico de Random Forest, un modelo de regresi√≥n log√≠stica y un modelo XGBoost. Seg√∫n las m√©tricas de evaluaci√≥n (precisi√≥n, recall, F1-score), Random Forest y XGBoost resultaron ser los modelos m√°s efectivos, alcanzando una alta capacidad de detecci√≥n. Una vez validado los modelos, se desarroll√≥ un pipeline para obtener datos en tiempo real desde la API de Alchemy y clasificar nuevas transacciones autom√°ticamente. Todo el desarrollo fue subido a un repositorio p√∫blico en GitHub, y como cierre del proyecto se implement√≥ una aplicaci√≥n web utilizando Streamlit. En esta app, los usuarios pueden ingresar un hash de transacci√≥n y seleccionar el modelo con el que desean clasificarla. De este modo, se integran todos los componentes del proyecto ‚Äîdesde el an√°lisis de datos hasta la interfaz de usuario‚Äî en una soluci√≥n funcional y accesible.


# üßæIntroducci√≥n

En el contexto actual del crecimiento exponencial de las criptomonedas, Ethereum se ha consolidado como una de las plataformas blockchain m√°s utilizadas a nivel global. Sin embargo, junto con su popularidad tambi√©n han aumentado las actividades fraudulentas en su red, como transacciones falsas, esquemas de phishing y otros tipos de estafas. Detectar este tipo de comportamiento en tiempo real es fundamental para proteger a los usuarios y mantener la integridad del ecosistema.

### üéØ Objetivo general

Desarrollar un sistema capaz de detectar autom√°ticamente transacciones fraudulentas en la red de Ethereum utilizando t√©cnicas de aprendizaje autom√°tico y aprendizaje profundo.

‚úÖ **Objetivos espec√≠ficos**

- Analizar y procesar un conjunto de datos reales de transacciones en Ethereum.
- Aplicar un an√°lisis exploratorio de datos (EDA) que permita comprender el comportamiento del conjunto y realizar una limpieza adecuada.
- Explorar y comparar distintos modelos de clasificaci√≥n, incluyendo redes neuronales, modelos construidos desde cero y modelos cl√°sicos como Random Forest o Regresi√≥n log√≠stica.
- Evaluar el desempe√±o de los modelos mediante m√©tricas est√°ndar (accuracy, precision, recall, F1-score).
- Seleccionar el o los modelos con mejor rendimiento, aplicando sobre √©l o ellos una validaci√≥n interna y un proceso de optimizaci√≥n de hiperpar√°metros.
- Obtener datos en tiempo real desde la API de Alchemy y preprocesarlos para que tengan la misma estructura y atributos que el dataset de entrenamiento.
- Aplicar el o los modelos entrenados, validados y optimizados a los datos externos para clasificar nuevas transacciones como fraudulentas o leg√≠timas.
- Subir todos los modelos, scripts de procesamiento, EDA, consultas a la API a un repositorio p√∫blico de GitHub para su disponibilidad y reutilizaci√≥n.
- Desarrollar una aplicaci√≥n web interactiva mediante Streamlit, donde los usuarios puedan consultar cualquier transacci√≥n en la red y seleccionar el modelo con el que desean hacer la predicci√≥n (aunque se recomienda el uso del modelo Random Forest por su mayor desempe√±o).

üß† **Justificaci√≥n del uso de redes neuronales**

El uso de redes neuronales se justifica por su capacidad para modelar patrones complejos y no lineales en grandes vol√∫menes de datos, como ocurre en las transacciones blockchain. A diferencia de los modelos cl√°sicos, las redes neuronales pueden captar relaciones sutiles entre m√∫ltiples variables que pueden pasar desapercibidas en otros enfoques. Este tipo de modelos ha demostrado un desempe√±o superior en tareas de detecci√≥n de anomal√≠as y clasificaci√≥n de eventos raros, como el fraude en redes descentralizadas. Por esta raz√≥n, el trabajo no solo implementa modelos tradicionales, sino que tambi√©n explora el potencial de redes neuronales desarrolladas desde cero y a trav√©s de frameworks como Keras.


# üìä Exploraci√≥n y an√°lisis de datos (EDA)

## üìå Descripci√≥n general del dataset

Cada fila representa una **cuenta √∫nica de Ethereum**, con estad√≠sticas agregadas sobre su comportamiento en transacciones y uso de tokens.

El dataset original cuenta con **51 columnas**, incluyendo la variable objetivo `FLAG`, que indica si una cuenta est√° asociada a actividad fraudulenta (`1`) o no (`0`). El dataset est√° **desbalanceado**, con una menor proporci√≥n de cuentas fraudulentas.

## üß∑ Significado de las columnas

| **Nombre de columna** | **Descripci√≥n** |
| --- | --- |
| `Address` | Direcci√≥n de la cuenta de Ethereum. |
| `FLAG` | Indica si la cuenta es fraudulenta (1) o no (0). |
| `Avg min between sent tnx` | Tiempo promedio entre transacciones enviadas (en minutos). |
| `Avg_min_between_received_tnx` | Tiempo promedio entre transacciones recibidas (en minutos). |
| `Time_Diff_between_first_and_last(Mins)` | Tiempo total entre la primera y √∫ltima transacci√≥n (en minutos). |
| `Sent_tnx` | Total de transacciones normales enviadas. |
| `Received_tnx` | Total de transacciones normales recibidas. |
| `Number_of_Created_Contracts` | Total de contratos creados por la cuenta. |
| `Unique_Received_From_Addresses` | N√∫mero de direcciones √∫nicas desde las que se recibi√≥ Ether. |
| `Unique_Sent_To_Addresses20` | N√∫mero de direcciones √∫nicas a las que se envi√≥ Ether. |
| `Min_Value_Received` | Valor m√≠nimo de Ether recibido. |
| `Max_Value_Received` | Valor m√°ximo de Ether recibido. |
| `Avg_Value_Received` | Valor promedio de Ether recibido. |
| `Min_Val_Sent` | Valor m√≠nimo de Ether enviado. |
| `Max_Val_Sent` | Valor m√°ximo de Ether enviado. |
| `Avg_Val_Sent` | Valor promedio de Ether enviado. |
| `Min_Value_Sent_To_Contract` | Valor m√≠nimo enviado a contratos. |
| `Max_Value_Sent_To_Contract` | Valor m√°ximo enviado a contratos. |
| `Avg_Value_Sent_To_Contract` | Valor promedio enviado a contratos. |
| `Total_Transactions(Including_Tnx_to_Create_Contract)` | Total de transacciones, incluidas las de creaci√≥n de contratos. |
| `Total_Ether_Sent` | Total de Ether enviado. |
| `Total_Ether_Received` | Total de Ether recibido. |
| `Total_Ether_Sent_Contracts` | Total de Ether enviado a contratos. |
| `Total_Ether_Balance` | Saldo final de Ether. |
| `Total_ERC20_Tnxs` | Total de transacciones de tokens ERC20. |
| `ERC20_Total_Ether_Received` | Total recibido en transacciones de tokens ERC20. |
| `ERC20_Total_Ether_Sent` | Total enviado en transacciones de tokens ERC20. |
| `ERC20_Total_Ether_Sent_Contract` | Total enviado a contratos en tokens ERC20. |
| `ERC20_Uniq_Sent_Addr` | Total de direcciones √∫nicas a las que se enviaron tokens ERC20. |
| `ERC20_Uniq_Rec_Addr` | Total de direcciones √∫nicas desde las que se recibieron tokens ERC20. |
| `ERC20_Uniq_Rec_Contract_Addr` | Total de contratos √∫nicos desde los que se recibieron tokens ERC20. |
| `ERC20_Avg_Time_Between_Sent_Tnx` | Tiempo promedio entre env√≠os de tokens ERC20. |
| `ERC20_Avg_Time_Between_Rec_Tnx` | Tiempo promedio entre recepciones de tokens ERC20. |
| `ERC20_Avg_Time_Between_Contract_Tnx` | Tiempo promedio entre transacciones hacia contratos en tokens ERC20. |
| `ERC20_Min_Val_Rec` | Valor m√≠nimo recibido en transacciones ERC20. |
| `ERC20_Max_Val_Rec` | Valor m√°ximo recibido en transacciones ERC20. |
| `ERC20_Avg_Val_Rec` | Valor promedio recibido en transacciones ERC20. |
| `ERC20_Min_Val_Sent` | Valor m√≠nimo enviado en transacciones ERC20. |
| `ERC20_Max_Val_Sent` | Valor m√°ximo enviado en transacciones ERC20. |
| `ERC20_Avg_Val_Sent` | Valor promedio enviado en transacciones ERC20. |
| `ERC20_Uniq_Sent_Token_Name` | N√∫mero de tipos √∫nicos de tokens enviados. |
| `ERC20_Uniq_Rec_Token_Name` | N√∫mero de tipos √∫nicos de tokens recibidos. |
| `ERC20_Most_Sent_Token_Type` | Tipo de token m√°s enviado. |
| `ERC20_Most_Rec_Token_Type` | Tipo de token m√°s recibido. |

## üß™ An√°lisis exploratorio inicial

### üîπ Inspecci√≥n general: `.info()`

Se identific√≥ que muchas columnas, especialmente de la 26 en adelante (relacionadas con tokens ERC20), contienen **valores nulos**.

- Las √∫ltimas columnas, como `ERC20_Most_Sent_Token_Type` y `ERC20_Most_Rec_Token_Type`, son categ√≥ricas con **alto porcentaje de nulos** y fueron eliminadas del an√°lisis.
- Los **valores nulos en variables num√©ricas** se imputaron con la media.

### üîÅ Correlaci√≥n cruzada entre `FLAG` y el resto de las variables

Se llev√≥ a cabo una **correlaci√≥n cruzada entre la variable `FLAG`** (indicador de fraude) y todas las dem√°s columnas del dataset. El objetivo era determinar qu√© tan relacionadas est√°n las caracter√≠sticas disponibles con la etiqueta de clasificaci√≥n.

### üìä Resultado:

- Todas las correlaciones cruzadas obtenidas entre `FLAG` y las dem√°s variables arrojaron **valores absolutos menores a 0.1**.
- Esto indica una **muy baja relaci√≥n lineal directa o inversa** con la variable objetivo.

### üìå Implicancias:

- La ausencia de una correlaci√≥n fuerte sugiere que **no hay atributos individuales que por s√≠ solos expliquen el fraude de manera lineal**.
- Este hallazgo **no implica que las variables sean in√∫tiles**, sino que **las relaciones relevantes pueden ser no lineales o depender de interacciones complejas**.

## üßπ Limpieza y reducci√≥n del dataset

### üî∏ Columnas con valores constantes (solo ceros)

Se eliminaron 7 columnas que conten√≠an exclusivamente valores 0:

- `ERC20 avg time between sent tnx`
- `ERC20 avg time between rec tnx`
- `ERC20 avg time between rec 2 tnx`
- `ERC20 avg time between contract tnx`
- `ERC20 min val sent contract`
- `ERC20 max val sent contract`
- `ERC20 avg val sent contract`

Estas columnas **no aportan varianza ni informaci√≥n √∫til al modelo**.

### üî∏ Columnas irrelevantes

Se eliminaron adem√°s:

- `Unnamed: 0`
- `Index`

por ser simplemente √≠ndices sin valor predictivo.

### üî∏ Eliminaci√≥n de columnas altamente correlacionadas

Se construy√≥ una matriz de correlaci√≥n y se eliminaron los siguientes pares redundantes (corr ‚â• 0.99):

| Par de columnas altamente correlacionadas | Columna eliminada |
| --- | --- |
| `max val sent to contract` ‚Äî `total ether sent contracts` | `max val sent to contract` |
| `ERC20 total Ether received` ‚Äî `ERC20 max val rec` | `ERC20 total Ether received` |
| `ERC20 max val sent` ‚Äî `ERC20 avg val sent` | `ERC20 max val sent` |
| `ERC20 min val sent` ‚Äî `ERC20 avg val sent` | `ERC20 min val sent` |
| `ERC20 total ether sent` ‚Äî `ERC20 max val sent` | `ERC20 total ether sent` |
| `ERC20 uniq rec contract addr` ‚Äî `ERC20 uniq rec token name` | `ERC20 uniq rec token name` |
| `ERC20 total ether sent` ‚Äî `ERC20 avg val sent` | ‚Äî (ya eliminada arriba) |

Estas columnas fueron eliminadas para reducir la **multicolinealidad** y simplificar el modelo.

![Matriz de correlaci√≥n](img/correlaci√≥n.png)


## üìä An√°lisis de balance y visualizaci√≥n

### Conteo de la variable `FLAG`:

‚úÖ **Resultados:**

- **Cuentas leg√≠timas (0):** 7662 (‚âà77.86%)
- **Cuentas fraudulentas (1):** 2179 (‚âà22.14%)

![Histograma de fraudes o no fraudes](img/Histograma.png)

Se confirma un **fuerte desbalance** de clases. Esto ser√° considerado durante el modelado (ponderaci√≥n, muestreo o m√©tricas apropiadas).

## üìÅ Resultado final

Tras el preprocesamiento:

- Se pas√≥ de **51 a 33 columnas**.
- Se conservaron √∫nicamente **columnas num√©ricas relevantes**.
- El dataset qued√≥ listo para aplicar modelos de clasificaci√≥n, con menor redundancia y mayor calidad.

### ‚úÖ Recomendaciones:

- Utilizar modelos capaces de capturar relaciones **no lineales y multidimensionales**, como:
    - Random Forest, Gradient Boosting, XGBoost.
    - Redes neuronales (MLP).


# Modelos:

## üß† Modelo de Red Neuronal

### üéØ Objetivo

Este modelo de red neuronal fue desarrollado para detectar fraudes en transacciones financieras. El modelo fue entrenado utilizando un conjunto de datos desbalanceado (`transaction_dataset_clean.csv`), y se implementaron t√©cnicas de preprocesamiento, normalizaci√≥n y ajuste de hiperpar√°metros. Se evaluaron dos enfoques: sin oversampling y con oversampling (SMOTE) para la mejora del rendimiento en la clase minoritaria (fraude).

 

### üì¶ Librer√≠as utilizadas

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report
from imblearn.over_sampling import SMOTE
```

### üßæ **Caracter√≠sticas del Modelo:**

- **Arquitectura de la Red Neuronal:**
    - Entrada: 32 neuronas
    - Ocultas: 20 neuronas
    - Salida: 2 neuronas
- **Activaciones:**
    - 'sigmoid' y 'tanh'
- **M√©todo de Entrenamiento:**
    - **Algoritmo:** Backpropagation con descenso del gradiente
    - **Aprendizaje Estoc√°stico**
    - **Criterio de Parada:** Convergencia del error
- **M√©tricas Evaluadas:**
    - Precisi√≥n
    - Recall
    - F1-Score
    - Accuracy
    - Matriz de confusi√≥n

### ‚öôÔ∏è Preprocesamiento

- Divisi√≥n en conjunto de entrenamiento y test (70/30).
- **Normalizaci√≥n** por media y desv√≠o est√°ndar usando `StandardScaler`.
- **One-hot encoding** aplicado a la variable objetivo.
- Codificaci√≥n de la salida en el rango `[-1, 1]` para adaptarse a `tanh`.

> Se prob√≥ tambi√©n usar SMOTE para balancear las clases en el entrenamiento.
> 

---

### üìä **Resultados Sin Oversampling:**

### **Matriz de Confusi√≥n (Test) y M√©tricas:**

```

[[2243   60]
 [  66  584]]

```

| Clase | Precision | Recall | F1-Score | Support |
| --- | --- | --- | --- | --- |
| **0** | 0.97 | 0.97 | 0.97 | 2303 |
| **1** | 0.91 | 0.90 | 0.90 | 650 |
| **Accuracy** |  |  | **0.96** | 2953 |
| **Macro Avg** | 0.94 | 0.94 | 0.94 | 2953 |
| **Weighted Avg** | 0.96 | 0.96 | 0.96 | 2953 |

### **An√°lisis:**

- **Generalizaci√≥n:** La peque√±a diferencia entre accuracy de entrenamiento (96.6%) y prueba (95.7%) sugiere que el modelo no est√° sobreajustado ni subajustado.
- **Desempe√±o en la clase 0 (no fraude):** Muy buen desempe√±o en esta clase debido a la mayor cantidad de ejemplos.
- **Desempe√±o en la clase 1 (fraude):** Aunque el recall es de 90%, hay margen para mejorar en la detecci√≥n de fraudes (falsos negativos).

---

### üìä **Resultados con Oversampling (SMOTE):**

### **M√©tricas Clave:**

- **Accuracy:** Entre 45% y 60% (bajo rendimiento).
- **Clase 1 (fraude):**
    - **Recall:** 0.99 (el modelo detecta casi todos los fraudes).
    - **Precision:** Muy baja, debido a un alto n√∫mero de falsos positivos.
- **M√©tricas Generales:**
    - **Precision, Recall y F1-Score:** En orden similar al accuracy, con una disminuci√≥n general del desempe√±o.

### **An√°lisis:**

- **Desempe√±o del Oversampling:** El modelo con SMOTE presenta un alto recall para la clase 1, pero este se logra a costa de muchos falsos positivos, lo que disminuye significativamente la precisi√≥n y el accuracy global.
- **Posible Causa:** El uso de SMOTE podr√≠a haber introducido datos sint√©ticos que no representan bien la distribuci√≥n real de la clase minoritaria (fraude), lo que afecta la generalizaci√≥n del modelo.

---

### üü¢ **Conclusiones:**

- **Modelo Sin Oversampling:**
    - El modelo tiene un excelente desempe√±o, con un buen balance entre precisi√≥n y recall, especialmente para la clase 0 (no fraude). El modelo detecta el 90% de los fraudes, lo que es un desempe√±o s√≥lido.
- **Modelo con Oversampling:**
    - El modelo con oversampling presenta un buen recall en la clase 1 (fraude), pero el modelo genera demasiados falsos positivos, afectando gravemente la precisi√≥n y el accuracy general.

### üìå Conclusi√≥n final

- El modelo sin oversampling es m√°s robusto y tiene un mejor rendimiento general, con un peque√±o ajuste en el recall de la clase 1 se podr√≠a mejorar la detecci√≥n de fraudes. El modelo con oversampling no se recomienda usarlo (al menos no en este tipo de problemas), ya que distorsiona la realidad, es decir, es natural que haya m√°s no fraudes que fraudes, por lo que al generar datos sint√©ticos se estar√≠a ‚Äúcontaminando‚Äù el dataset.


## ü§ñ Modelo de Red Neuronal con Keras

### üéØ Objetivo

Probar un modelo de red neuronal usando Keras sobre el dataset limpio (`transaction_dataset_clean.csv`) y comparar sus resultados con el modelo desarrollado a mano anteriormente.

---

### üì¶ Librer√≠as utilizadas

```python

import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

```

---

### üßæ Estructura del modelo

- **Entradas:** 32 atributos (features)
- **Capa oculta:** 1 capa con 20 neuronas, activaci√≥n `sigmoid`
- **Capa de salida:** 2 neuronas, activaci√≥n `tanh`
- **Optimizaci√≥n:** `SGD`
- **Funci√≥n de p√©rdida:** `mean_squared_error`
- **M√©tricas:** Accuracy, Precision, Recall, F1-score

---

### ‚öôÔ∏è Preprocesamiento

- Divisi√≥n en conjunto de entrenamiento y test (70/30).
- **Normalizaci√≥n** por media y desv√≠o est√°ndar usando `StandardScaler`.
- **One-hot encoding** aplicado a la variable objetivo.
- Codificaci√≥n de la salida en el rango `[-1, 1]` para adaptarse a `tanh`.

> Se prob√≥ tambi√©n usar SMOTE para balancear las clases en el entrenamiento.
> 

---

### üìä Resultados sin SMOTE

**Matriz de confusi√≥n (Test):**

```

[[2277   26]
 [ 363  287]]

```

**Reporte de clasificaci√≥n:**

| Clase | Precision | Recall | F1-score | Soporte |
| --- | --- | --- | --- | --- |
| 0 | 0.86 | 0.99 | 0.92 | 2303 |
| 1 | 0.91 | 0.44 | 0.59 | 650 |
- **Accuracy:** 0.87
- **Macro avg F1:** 0.76
- **Weighted avg F1:** 0.85

üî¥ **Conclusi√≥n sin SMOTE:**

El modelo no logra buenos resultados para la clase 1 (fraude). Predice bien la clase mayoritaria, pero falla mucho en la minoritaria: m√°s de la mitad de los fraudes no se detectan. Aunque el accuracy es razonable, no refleja el verdadero desempe√±o debido al desbalance de clases.

---

### üìä Resultados con SMOTE

**Matriz de confusi√≥n (Test):**

```
lua
CopiarEditar
[[1891  412]
 [  76  574]]

```

**Reporte de clasificaci√≥n:**

| Clase | Precision | Recall | F1-score | Soporte |
| --- | --- | --- | --- | --- |
| 0 | 0.96 | 0.82 | 0.89 | 2303 |
| 1 | 0.58 | 0.88 | 0.70 | 650 |
- **Accuracy:** 0.83
- **Macro avg F1:** 0.79
- **Weighted avg F1:** 0.85

üü¢ **Conclusi√≥n con SMOTE:**

El modelo mejora sustancialmente en la detecci√≥n de fraudes. El recall y el F1-score de la clase 1 aumentan considerablemente, lo cual es clave en este tipo de problemas. Aunque el accuracy general baja, el modelo es m√°s justo y √∫til para el prop√≥sito del an√°lisis.

---

### üìå Conclusiones generales

- Se prob√≥ una arquitectura muy similar a la red neuronal desarrollada a mano.
- Los resultados sin t√©cnicas de balanceo no fueron buenos para la clase 1.
- SMOTE mejor√≥ considerablemente la detecci√≥n de fraudes, sin embargo, hay que tener en cuenta que al generar datos sint√©ticos no se est√° reflejando la realidad del problema, es decir, es natural que haya menos fraudes que no fraudes. Por lo que con t√©cnicas de oversampling se estar√≠a ‚Äúcontaminando‚Äù el dataset, adem√°s los resultados tampoco fueron muy buenos en comparaci√≥n con el modelo de red neuronal desarrollado anteriormente.


## üå≤ Modelo Random Forest

### üéØ Objetivo

Probar un modelo cl√°sico de machine learning usando Random Forest sobre el dataset limpio (`transaction_dataset_clean.csv`) y comparar sus resultados con los modelos desarrollados anteriormente.

### üì¶ Librer√≠as utilizadas

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier                                      
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc      
from sklearn.model_selection import train_test_split, RandomizedSearchCV             
import matplotlib.pyplot as plt

```

### üß™ Desarrollo del modelo

### 1. **Preparaci√≥n de los datos**

- Se utiliz√≥ el dataset limpio con el que se ven√≠a trabajando.
- Se separ√≥ la variable objetivo `'FLAG'` del resto de los predictores.
- Se aplic√≥ una divisi√≥n **estratificada** del dataset:
    - 70% para entrenamiento
    - 15% para validaci√≥n
    - 15% para test

```python

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)

```

### 2. **Normalizaci√≥n**

- Se normalizaron los datos con `StandardScaler`, ajustando solo sobre el conjunto de entrenamiento y transformando el resto.

```python

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

```

### 3. **Entrenamiento inicial**

- Se entren√≥ un primer modelo base de `RandomForestClassifier` con 100 √°rboles para evaluar desempe√±o preliminar.
- M√©tricas mostraron un rendimiento alto desde el inicio.

### 4. **Optimizaci√≥n de hiperpar√°metros**

- Se utiliz√≥ `RandomizedSearchCV` para encontrar la mejor combinaci√≥n de hiperpar√°metros con `class_weight='balanced'`.
- Se us√≥ validaci√≥n cruzada con 5 folds sobre el conjunto de **validaci√≥n**, no sobre el de entrenamiento, para evitar sobreajuste.

```python

random_search = RandomizedSearchCV(
    estimator=RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1),
    param_distributions=param_grid,
    n_iter=20,
    cv=5,
    verbose=2,
    random_state=42,
    n_jobs=-1
)
random_search.fit(X_val, y_val)
```

### 5. **Evaluaci√≥n del modelo optimizado**

- Se reentren√≥ el modelo con los **mejores hiperpar√°metros** encontrados sobre el conjunto de entrenamiento.
- Se evalu√≥ el desempe√±o en el conjunto de test.

```python

rf_opt = RandomForestClassifier(**mejores_params, class_weight='balanced', random_state=42, n_jobs=-1)
rf_opt.fit(X_train, y_train)
y_test_pred = rf_opt.predict(X_test)

```

---

### üìà Resultados en conjunto de test

**Matriz de confusi√≥n:**

```

[[1146    4]
 [  21  306]]

```

**Reporte de clasificaci√≥n:**

| Clase | Precision | Recall | F1-Score | Soporte |
| --- | --- | --- | --- | --- |
| 0 (no fraude) | 0.98 | 1.00 | 0.99 | 1150 |
| 1 (fraude) | 0.99 | 0.94 | 0.96 | 327 |
| **Accuracy global** |  |  | **0.98** | 1477 |

---

### üìå An√°lisis y Justificaci√≥n

### ¬øEl modelo puede mejorar m√°s?

El modelo alcanza un desempe√±o excelente, sobre todo en la clase minoritaria (fraude):

- **Precisi√≥n: 0.99** ‚Üí casi ning√∫n falso positivo.
- **Recall: 0.94** ‚Üí detecta 94% de los fraudes.
- **F1-score: 0.96** ‚Üí excelente equilibrio entre precisi√≥n y recall.

### ¬øAplicar SMOTE?

Se decidi√≥ **no aplicar t√©cnicas como SMOTE**, por los siguientes motivos:

- El modelo ya detecta fraudes con alto rendimiento.
- Generar fraudes sint√©ticos **distorsionar√≠a la distribuci√≥n real del problema**, que es naturalmente desbalanceada.
- Es preferible que el modelo aprenda en el contexto realista, donde el fraude ocurre 1 de cada 5 veces o menos.

### ¬øBajar el umbral de decisi√≥n?

Tambi√©n se decidi√≥ **no modificar el umbral predeterminado (0.5)**:

- Bajar el umbral podr√≠a aumentar el recall, pero **a costa de muchos m√°s falsos positivos**, lo que no es aceptable en este contexto.
- Dado el balance actual entre precisi√≥n y recall, **el valor por defecto del umbral es razonable**.
- Incluso se consider√≥ que **subir** el umbral podr√≠a tener m√°s sentido si se buscara a√∫n m√°s certeza ante una predicci√≥n de fraude.

---

### üìé Conclusi√≥n

El modelo ha sido optimizado correctamente, alcanzando m√©tricas sobresalientes en un problema desbalanceado. Se considera que **ya lleg√≥ a su l√≠mite razonable de mejora**, y se justifica **no aplicar t√©cnicas adicionales como SMOTE ni modificar el umbral de clasificaci√≥n**.

El modelo es robusto, eficiente y confiable para detectar fraudes con alta precisi√≥n sin comprometer la tasa de falsos positivos.

## üìà Modelo Regresi√≥n Log√≠stica

### üìã Objetivo

El objetivo de este modelo fue detectar transacciones fraudulentas utilizando un enfoque supervisado de clasificaci√≥n binaria mediante regresi√≥n log√≠stica. Se aplicaron distintas estrategias para abordar el problema del desbalance de clases.

---

### üß™ Dataset

- Se utiliz√≥ un dataset de transacciones (`transaction_dataset_clean.csv`) donde la variable objetivo es `FLAG` (0: Sin fraude, 1: Con fraude).
- Se aplicaron transformaciones con `get_dummies()` para convertir variables categ√≥ricas en variables num√©ricas.
- Divisi√≥n de los datos:
    - Entrenamiento: 30%
    - Test: 70%

---

### ‚öôÔ∏è Modelo base (sin balanceo)

- **Clasificador**: `LogisticRegression` (penalizaci√≥n L2, solver: newton-cg)
- **M√©trica principal**: F1-score, especialmente para la clase minoritaria (fraude)

### Resultados:

| Clase | Precisi√≥n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.85 | 1.00 | 0.92 |
| Con fraude | 0.99 | 0.37 | 0.54 |
| **Accuracy** | **0.86** |  |  |

üîé **Observaci√≥n**: Alta precisi√≥n pero baja recuperaci√≥n de fraudes (recall 0.37), t√≠pico en datasets desbalanceados.

---

### ‚öñÔ∏è Estrategias de Balanceo

### üìç 1. Penalizaci√≥n (`class_weight="balanced"`)

- Ajuste autom√°tico de pesos inversamente proporcionales a la frecuencia de las clases.

**Resultados:**

| Clase | Precisi√≥n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.88 | 0.98 | 0.93 |
| Con fraude | 0.90 | 0.53 | 0.67 |
| **Accuracy** | **0.88** |  |  |

‚úÖ **Mejora significativa del recall en la clase minoritaria.**

---

### üìç 2. Under-Sampling (NearMiss)

- Reducci√≥n de la clase mayoritaria para igualar la cantidad de muestras.

**Resultados:**

| Clase | Precisi√≥n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.98 | 0.36 | 0.53 |
| Con fraude | 0.30 | 0.97 | 0.46 |
| **Accuracy** | **0.50** |  |  |

‚ö†Ô∏è **Muy bajo rendimiento general. Aunque mejora el recall de fraudes, baja mucho la precisi√≥n.**

---

### üìç 3. Over-Sampling (RandomOverSampler)

- R√©plica de muestras de la clase minoritaria.

**Resultados:**

| Clase | Precisi√≥n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.88 | 0.98 | 0.93 |
| Con fraude | 0.87 | 0.54 | 0.67 |
| **Accuracy** | **0.88** |  |  |

‚úÖ **Resultados similares al caso de penalizaci√≥n. Mejora sin afectar negativamente el modelo.**

---

### üìç 4. Ensamble Balanceado (BalancedBaggingClassifier)

- Uso de m√∫ltiples modelos con muestreo balanceado interno.

**Resultados:**

| Clase | Precisi√≥n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.98 | 0.97 | 0.98 |
| Con fraude | 0.91 | 0.94 | 0.92 |
| **Accuracy** | **0.97** |  |  |

üèÜ **Mejor estrategia de todas**: Alt√≠sima precisi√≥n y recall para ambas clases.

---

### üìà Conclusi√≥n

- El modelo de regresi√≥n log√≠stica sin balancear **no es suficiente** para detectar fraudes de forma efectiva.
- Las estrategias de **penalizaci√≥n** y **oversampling** logran mejoras considerables.
- La mejor performance se logr√≥ con **BalancedBaggingClassifier**, obteniendo un excelente balance entre precisi√≥n y recall.
- El tratamiento del desbalance de clases es **crucial** para problemas de detecci√≥n de fraude.

## ‚ö° Modelo XGBoost

### üìå Objetivo

El script entrena y eval√∫a un modelo de clasificaci√≥n con distintos enfoques de balanceo de clases para detectar transacciones fraudulentas en un dataset desbalanceado.

---

### üß© Dependencias

- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `sklearn`: m√©tricas, split de datos
- `xgboost`
- `imblearn`: t√©cnicas de resampling y ensemble

---

### üß∂ Estructura del Script

### 1. **Carga de Datos**

Se carga un archivo CSV con datos de transacciones. Se imprime la dimensi√≥n del dataset y la distribuci√≥n de clases (`FLAG`: 0 = no fraude, 1 = fraude).

```python

df = pd.read_csv("../../datasets/transaction_dataset.csv")
```

### 2.**Preprocesamiento**

- Se eliminan columnas irrelevantes (`Unnamed: 0`, `Index`).
- Se filtran s√≥lo columnas num√©ricas.
- Se imputan valores faltantes con la media.
- Se separan las variables predictoras (`X`) de la variable objetivo (`y`).
- Se divide el dataset en entrenamiento y prueba (70% test, estratificado).

---

### 3. **Definici√≥n de Funciones**

- `run_xgb_model(...)`: entrena un modelo `XGBClassifier`, con opci√≥n de ajustar el par√°metro `scale_pos_weight` para desbalanceo.
- `show_results(...)`: genera la matriz de confusi√≥n y m√©tricas de evaluaci√≥n (`precision`, `recall`, `f1-score`).

---

### ‚öôÔ∏è Estrategias de Balanceo Probadas

Cada bloque entrena un modelo XGBoost con una estrategia distinta de balanceo. Se eval√∫an con el mismo conjunto de prueba.

| Estrategia | Descripci√≥n |
| --- | --- |
| üîπ Sin balanceo | Modelo base, sin ajuste por desbalanceo. |
| üîπ `scale_pos_weight` | Ajuste de peso para la clase minoritaria (fraude). |
| üîπ Under-sampling | Usa `NearMiss()` para reducir la clase mayoritaria. |
| üîπ Over-sampling | Usa `RandomOverSampler()` para duplicar muestras de la clase minoritaria. |
| üîπ SMOTE-Tomek | Combinaci√≥n de oversampling (SMOTE) y limpieza (Tomek links). |
| üîπ Ensemble balanceado | Usa `BalancedBaggingClassifier` con `XGBClassifier` como modelo base. |

---

### üìä Resultados

Cada modelo genera:

- Matriz de confusi√≥n
- M√©tricas de clasificaci√≥n (`precision`, `recall`, `f1-score`) por clase

### üìä Comparaci√≥n de Resultados - Modelo XGBoost

| M√©todo | Clase | Precision | Recall | F1-score | Accuracy |
| --- | --- | --- | --- | --- | --- |
| **1. Sin Balanceo** | Sin fraude | 0.98 | 0.99 | 0.99 |  |
|  | Con fraude | 0.98 | 0.93 | 0.95 | **0.98** |
|  | **Macro Avg** | **0.98** | 0.96 | 0.97 |  |
|  | **Weighted** | **0.98** | 0.98 | 0.98 |  |
| **2. Scale Pos Weight** | Sin fraude | 0.98 | 0.99 | 0.99 |  |
|  | Con fraude | 0.97 | 0.95 | 0.96 | **0.98** |
|  | **Macro Avg** | **0.98** | 0.97 | 0.97 |  |
|  | **Weighted** | **0.98** | 0.98 | 0.98 |  |
| **3. Under-sampling** | Sin fraude | 1.00 | 0.58 | 0.73 |  |
|  | Con fraude | 0.40 | 1.00 | 0.57 | **0.67** |
|  | **Macro Avg** | **0.70** | 0.79 | 0.65 |  |
|  | **Weighted** | **0.87** | 0.67 | 0.70 |  |
| **4. Over-sampling** | Sin fraude | 0.98 | 0.99 | 0.99 |  |
|  | Con fraude | 0.97 | 0.94 | 0.95 | **0.98** |
|  | **Macro Avg** | **0.98** | 0.97 | 0.97 |  |
|  | **Weighted** | **0.98** | 0.98 | 0.98 |  |
| **5. Ensemble Balanceado** | Sin fraude | 0.99 | 0.98 | 0.98 |  |
|  | Con fraude | 0.94 | 0.96 | 0.95 | **0.98** |
|  | **Macro Avg** | **0.96** | 0.97 | 0.97 |  |
|  | **Weighted** | **0.98** | 0.98 | 0.98 |  |

---

### üìù Observaciones clave:

- **Sin balanceo**, el modelo ya ten√≠a un rendimiento muy alto, pero con **falsos negativos** m√°s marcados (recall m√°s bajo para fraudes).
- **`scale_pos_weight` y `Over-sampling`** mejoran el recall para la clase minoritaria (`Con fraude`), manteniendo la precisi√≥n general.
- **Under-sampling** causa una gran p√©rdida de precisi√≥n para la clase minoritaria, aunque logra alto recall (predice todos los fraudes, pero con muchos falsos positivos).
- **Balanced Bagging Ensemble** ofrece un muy buen equilibrio entre clases, con **mejor precision-recall para fraudes** sin sacrificar demasiado la clase mayoritaria.

### üß† Conclusi√≥n final:

> El m√©todo de Balanced Bagging Ensemble es el m√°s robusto y efectivo para el modelo XGBoost, ya que logra un balance √≥ptimo entre precisi√≥n y recall para ambas clases, lo cual es esencial en tareas sensibles como la detecci√≥n de fraude. Ofrece alta capacidad de detecci√≥n sin comprometer la fiabilidad general del sistema.


# üß† Comparaci√≥n de modelos

üßæ A lo largo del proyecto se evaluaron varios enfoques distintos para la detecci√≥n de fraudes: un modelo de regresi√≥n log√≠stica, una red neuronal implementada manualmente, una red neuronal utilizando Keras, un modelo cl√°sico de Machine Learning basado en Random Forest y un modelo XGBoost. Cada uno de estos modelos fue probado tanto con como sin t√©cnicas de balanceo como oversampling (excepto el modelo de Random Forest), undersampling, etc y se analizaron sus resultados de manera integral.

üß† Regresi√≥n log√≠stica s**in balanceo**

Alta precisi√≥n para la clase *sin fraude* (0.98), pero muy bajo recall para *fraude* (0.17). Tiene alta exactitud general (0.89), pero pr√°cticamente no detecta fraudes. Inadecuado para contextos donde el recall en la clase minoritaria es clave.

üß† Regresi√≥n log√≠stica con **`class_weight='balanced'`**

Mejora el recall de *fraude* (0.71), pero con baja precisi√≥n (0.29), lo que genera muchos falsos positivos. Aumenta la sensibilidad al fraude, sacrificando exactitud global (0.73). √ötil cuando se prioriza no perder fraudes. 

üß† Regresi√≥n log√≠stica con **Under-sampling (NearMiss)**

Muy alto recall en *fraude* (0.99), pero muy baja precisi√≥n (0.29), afectando fuertemente la exactitud (0.67). Aumenta sensibilidad, pero a costa de generar muchos errores de clasificaci√≥n. Solo recomendable si detectar fraudes a toda costa es la prioridad.

üß† Regresi√≥n log√≠stica con **Over-sampling (RandomOverSampler)** 

Buen balance entre precisi√≥n y recall: 0.94 y 0.73 para *fraude* respectivamente. Accuracy global aceptable (0.92). Riesgo leve de overfitting, pero rendimiento general estable.

üß† Regresi√≥n log√≠stica con **Balanced Bagging**

F1-score alto en *fraude* (0.85) con buen balance entre precisi√≥n (0.86) y recall (0.83). Accuracy alta (0.95), sin comprometer la detecci√≥n de fraudes. Mejor opci√≥n global: logra equilibrio sin modificar la distribuci√≥n de test. Siendo esta variante la mejor opci√≥n para este modelo, arrojando las mejores m√©tricas.

üß† **XGBoost sin balanceo**

Muy alta precisi√≥n (0.98) y accuracy (0.98), pero recall para *fraude* algo limitado (0.93). F1-score en fraude de 0.95. Rinde muy bien, pero tiende a favorecer la clase mayoritaria.

üß† **XGBoost con `scale_pos_weight`** 

Mejora el recall en *fraude* a 0.95 manteniendo precisi√≥n alta (0.97). F1-score en *fraude* de 0.96, accuracy total de 0.98. Excelente opci√≥n para ajustar desequilibrio leve-moderado sin alterar los datos. 

üß† **XGBoost con Under-sampling (NearMiss)**

Recall perfecto en *fraude* (1.00), pero precisi√≥n muy baja (0.40) y accuracy general baja (0.67). F1-score de 0.57 en fraude. √ötil en casos donde no se puede permitir pasar un fraude, pero muy ineficiente globalmente.

üß† **XGBoost con Over-sampling (RandomOverSampler)** 

Alto rendimiento: precisi√≥n de 0.97 y recall de 0.94 en *fraude*, F1-score de 0.95. Accuracy estable en 0.98. Buena opci√≥n con bajo riesgo de overfitting en este caso.

üß† **XGBoost con Balanced Bagging** 

Gran equilibrio: precisi√≥n (0.94), recall (0.96), F1-score (0.95) en *fraude*. Accuracy total muy alta (0.98). Mejor alternativa general, detecta fraudes sin afectar negativamente el rendimiento global. Siendo esta variante la mejor opci√≥n para este modelo, arrojando las mejores m√©tricas.

üß† **Red neuronal implementada manualmente (sin oversampling)**

Este modelo mostr√≥ un muy buen desempe√±o general. Con una accuracy del 95.7% en el conjunto de prueba, y valores altos de precisi√≥n y recall para ambas clases (f1-score de 0.90 para la clase de fraude), demostr√≥ una buena capacidad de generalizaci√≥n sin indicios de sobreajuste. La diferencia m√≠nima entre accuracy de entrenamiento (0.966) y prueba (0.957) refuerza esta observaci√≥n. Fue el modelo con mejor desempe√±o dentro del enfoque de redes neuronales.

üß† **Red neuronal implementada manualmente (con SMOTE)**

Al aplicar oversampling con SMOTE, el modelo mostr√≥ un fuerte deterioro en el rendimiento general. Aunque se logr√≥ un recall de 0.99 para la clase de fraude (lo que indica que detect√≥ casi todos los fraudes), esto vino acompa√±ado de una ca√≠da severa en el accuracy general (entre 45% y 60%) y un aumento significativo de falsos positivos. Esto sugiere que los datos sint√©ticos generados no representaron adecuadamente la clase minoritaria, afectando la capacidad del modelo de generalizar.

üß† **Red neuronal con Keras (sin oversampling)**

El modelo desarrollado con Keras, a pesar de tener una estructura similar al modelo implementado a mano, present√≥ peores resultados. Aunque el accuracy se mantuvo aceptable (87%), el desempe√±o sobre la clase minoritaria fue claramente inferior: el modelo solo detect√≥ correctamente 287 de los 650 fraudes. El f1-score de la clase 1 fue de 0.59, reflejando una baja sensibilidad.

üß† **Red neuronal con Keras (con SMOTE)**

Con oversampling, el rendimiento sobre la clase minoritaria mejor√≥ considerablemente (recall de 0.88 y f1-score de 0.70), aunque a costa de una ca√≠da en la precisi√≥n (aumento de falsos positivos) y un descenso general en el accuracy (83%). Este escenario muestra una compensaci√≥n favorable en t√©rminos de justicia con la clase minoritaria, aunque a√∫n por debajo del rendimiento de otros modelos.

üß† **Random Forest (sin oversampling)**

Los resultados obtenidos con Random Forest fueron los m√°s destacados de todos los modelos probados. Se alcanz√≥ un accuracy del 98%, con una excelente capacidad para clasificar correctamente ambas clases (f1-score de 0.96 para la clase de fraude). El modelo demostr√≥ una robustez sorprendente sin necesidad de normalizaci√≥n ni t√©cnicas de oversampling, y present√≥ una curva ROC con AUC ‚âà 1.00, lo que indica una separaci√≥n casi perfecta entre clases.

### üìä Comparaci√≥n de M√©tricas

| M√©trica | Red Neuronal  | Keras | Random Forest | Regresi√≥n log√≠stica (**Balanced Bagging**) | XGBoost (**Balanced Bagging**) |
| --- | --- | --- | --- | --- | --- |
| Accuracy | 0.95 | 0.87 | 0.98 | 0.97 | 0.98 |
| Precision clase 0 | 0.96 | 0.86 | 0.98 | 0.98 | 0.99 |
| Recall clase 0 | 0.98 | 0.99 | 1 | 0.97 | 0.98 |
| F1-score clase 0 | 0.97 | 0.92 | 0.99 | 0.98 | 0.98 |
| Presicion clase 1 | 0.93 | 0.92 | 0.99 | 0.91 | 0.94 |
| Recall clase 1 | 0.86 | 0.44 | 0.94 | 0.94 | 0.96 |
| F1-score clase 1 | 0.89 | 0.60 | 0.96 | 0.92 | 0.95 |
| Macro avg F1-score | 0.93 | 0.76 | 0.97 | 0.95 | 0.97 |
| Weighted avg F1-score | 0.95 | 0.85 | 0.98 | 0.97 | 0.98 |

---

### üìå Conclusi√≥n

Dado el desempe√±o superior en t√©rminos de precisi√≥n, recall, f1-score y robustez general, se eligi√≥ **Random Forest** y **XGBoost (Balanced Bagging)** como modelos fiables para el proyecto, aunque el modelo de regresi√≥n log√≠stica (**Balanced Bagging**) tiene muy buenas m√©tricas y la red neuronal tambi√©n es buena opci√≥n. A diferencia de las redes neuronales, y el de regresi√≥n log√≠stica, Random Forest no requiri√≥ t√©cnicas adicionales de balanceo ni normalizaci√≥n (aunque al normalizar los datos, el modelo de random forest pas√≥ de presentar un valor de 0.93 en racall para fraude a 0.94, es decir, mejor√≥).

# Obtenci√≥n de datos de Alchemy

### üßæ Script de Extracci√≥n de Features de Transacciones Ethereum

Este script permite obtener transacciones recientes en la red Ethereum usando la API de Alchemy, identificar direcciones involucradas, recuperar sus transacciones hist√≥ricas y generar un conjunto de features √∫tiles para an√°lisis y modelos predictivos.

```jsx
scripts/extract_eth_features.py
```

### ‚öôÔ∏è Requisitos

- Python 3.7+
- Paquetes:

```jsx
pip install requests pandas
```

### üîë Configuraci√≥n

Edit√° la variable `ALCHEMY_API_KEY` en el script con tu propia clave de API de [Alchemy](https://www.alchemy.com/).

```jsx
ALCHEMY_API_KEY = "TU_API_KEY_AQUI"
```

### üß† Qu√© hace el script

1. Consulta las transacciones externas y ERC20 m√°s recientes de la red Ethereum (√∫ltimo minuto).
2. Extrae todas las direcciones (`from` y `to`) involucradas.
3. Descarga transacciones hist√≥ricas de cada direcci√≥n encontrada.
4. Calcula estad√≠sticas y features relevantes como:
    - Totales y promedios de ETH enviados/recibidos
    - Tokens √∫nicos utilizados
    - Tiempos entre transacciones
    - Token ERC20 m√°s utilizado
5. Guarda los resultados como un archivo CSV.

---

### ‚ñ∂Ô∏è C√≥mo usar

```jsx
python scripts/extract_eth_features.py
```

Esto generar√° un archivo llamado `historical_features_eth.csv`, con una fila por direcci√≥n y m√©tricas √∫tiles como:

- `Avg_Value_Received`
- `Max_Val_Sent`
- `ERC20_Most_Rec_Token_Type`
- `Time_Diff_between_first_and_last(Mins)`
- ...y muchos m√°s.

### üìå Consideraciones

- Cada direcci√≥n se consulta individualmente, lo que puede demorar si hay muchas direcciones.
- Se incluye un `sleep(0.2)` para evitar l√≠mites de tasa de Alchemy.
- El n√∫mero de transacciones hist√≥ricas recuperadas por address es configurable con `max_tx`.

### üõ†Ô∏è Personalizaci√≥n

Se puede modificar:

- El per√≠odo reciente de transacciones (`minutes=1`)
- La cantidad de transacciones hist√≥ricas por direcci√≥n (`max_tx=100`)
- Los features calculados en la funci√≥n `extract_features`

### Creaci√≥n de datos para probar con los distintos modelos

El dataset limpio con el que estamos ejecutando el modelo (`transaction_dataset_clean.csv`) tiene las siguientes columnas:

- Avg min between sent tnx
- Avg min between received tnx
- Time Diff between first and last (Mins)
- Sent tnx
- Received Tnx
- Number of Created Contracts
- Unique Received From Addresses
- Unique Sent To Addresses
- min value received
- max value received
- avg val received
- min val sent
- max val sent
- avg val sent
- min value sent to contract
- avg value sent to contract
- total transactions (including tnx to create contract)
- total Ether sent
- total ether received
- total ether sent contracts
- total ether balance
- Total ERC20 tnxs
- ERC20 total Ether sent contract
- ERC20 uniq sent addr
- ERC20 uniq rec addr
- ERC20 uniq sent addr.1
- ERC20 uniq rec contract addr
- ERC20 min val rec
- ERC20 max val rec
- ERC20 avg val rec'
- ERC20 avg val sent
- ERC20 uniq sent token name

# üìä Resultados dataset externo

Se trabaj√≥ con un **dataset externo (obtenido de la p√°gina de Alchemy) compuesto por 580 muestras** para determinar si alguna de las transacciones result√≥ fraudolenta, de acuerdo a los modelos desarrollados en el proyecto: un **Random Forest**, una **Red Neuronal con Keras** y una **Red Neuronal implementada manualmente,** una **Regresi√≥n log√≠stica** y un **XGBoost**. A continuaci√≥n se detallan los resultados obtenidos con cada modelo y un an√°lisis comparativo.

---

### üå≤ Modelo 1: Random Forest

- **Resumen de resultados:**
    - M√°s de **300 muestras** arrojaron una probabilidad de fraude de aproximadamente **27%**.
    - Cerca de **150 muestras** se ubicaron alrededor del **39%** de probabilidad.
    - Las restantes muestras se distribuyeron entre **0% y 43%**, siendo muy pocas.
    
    ![Probabilidad con Random Forest](img/rf.png)
    
- **An√°lisis:**
    - Este modelo **no muestra una evidencia clara** de fraude en las transacciones evaluadas.
    - Las probabilidades se mantienen en un rango medio sin alcanzar valores extremos.
    - A pesar de la distribuci√≥n, **este fue uno de los modelos con mejores m√©tricas**, cercanas a la perfecci√≥n.
- **Conclusi√≥n parcial:**
    
    > Si bien el modelo detecta ciertos patrones, no hay elementos concluyentes para afirmar que existan transacciones fraudulentas. Su alta precisi√≥n refuerza la idea de una clasificaci√≥n conservadora pero confiable.
    > 

---

### ü§ñ Modelo 2: Red Neuronal con Keras

- **Resumen de resultados:**
    - Aproximadamente **400 muestras** dieron menos del **10%** de probabilidad de fraude.
    - M√°s de **150 muestras** se ubicaron entre el **40% y 45%**.
    - Algunas muestras incluso superaron el **90%** de probabilidad.

![Probabilidad con keras](img/keras.png)

- **An√°lisis:**
    - A pesar de detectar algunas transacciones con alta probabilidad, **las m√©tricas generales del modelo fueron malas**.
    - El modelo **carece de confiabilidad** para identificar fraudes con certeza.
    - Es probable que est√© reaccionando de forma espuria a patrones que no son relevantes.
- **Conclusi√≥n parcial:**
    
    > No se recomienda utilizar este modelo como referencia para detectar fraude, ya que sus resultados no est√°n respaldados por un desempe√±o s√≥lido en m√©tricas.
    > 

---

### üß† Modelo 3: Red Neuronal Manual

- **Resumen de resultados:**
    - M√°s de **400 muestras** colapsan cerca de **0** (no fraude).
    - **146 muestras** se ubican por encima del **75%**, cercanas a **1** (fraude).

![Probabilidad con Red Neuronal](img/red.png)

- **An√°lisis:**
    - Este modelo fue dise√±ado para colapsar hacia extremos (0 o 1), logrando una **discriminaci√≥n clara** entre clases.
    - Present√≥ **muy buenas m√©tricas** (aunque inferiores al Random Forest, Regresi√≥n Log√≠stica y XGBoost).
    - El resultado refleja una distribuci√≥n **coherente con la del dataset original**, donde aproximadamente el **22% eran fraudes**. En este caso cerca del 25% de las transacciones ser√≠an fraudolentas.
- **Conclusi√≥n parcial:**
    
    > El modelo representa de forma realista la proporci√≥n esperada de fraudes, mostrando un comportamiento robusto ante el dataset externo, aunque no es tan preciso como los modelos de Random Forest, Regresi√≥n Log√≠stica y XGBoost.
    > 

---

### üìà Modelo 4: Regresi√≥n Log√≠stica (Balanced Bagging)

- **Resumen de resultados:**
    - 566 muestras tuvieron una probabilidad de fraude menor al 10%.
    - Pocas muestras tuvieron una probabilidad mayor al 50%, solo 8 muestras con una probabilidad del 80%.

![Probabilidad con Regresi√≥n log√≠stica](img/regresi√≥n.png)

- **An√°lisis:**
    - Present√≥ **muy buenas m√©tricas** (aunque levemente inferiores al Random Forest y XGBoost).
    - **Distribuci√≥n**: Extremadamente similar a la de **XGBoost**, con una gran acumulaci√≥n en zona no fraude.
- **Conclusi√≥n parcial:**
    
    > **Modelo confiable en m√©tricas**, y muy prudente en nuevas predicciones. Junto a XGBoost, revela un patr√≥n com√∫n de detecci√≥n extremadamente conservadora.
    > 

---

### ‚ö°  Modelo 5: XGBoost (Balanced Bagging)

- **Resumen de resultados:**
    - 566 muestras tuvieron una probabilidad de fraude menor al 10%.
    - Pocas muestras tuvieron una probabilidad mayor al 50%, solo 4 muestras con una probabilidad mayor al 78% y una de ellas alcanza el 90%.

![Probabilidad con XGBoost](img/XGBoost.png)

- **An√°lisis:**
    - Junto con Random Forest present√≥ las mejores m√©tricas.
    - **Distribuci√≥n**: Extremadamente similar a la de Regresi√≥n Log√≠stica, con una gran acumulaci√≥n en zona no fraude.
- **Conclusi√≥n parcial:**
    
    > **Modelo muy confiable**. A pesar de su bajo n√∫mero de predicciones de fraude, lo hace con alta seguridad. Su distribuci√≥n refleja un comportamiento predecible y s√≥lido, en l√≠nea con Regresi√≥n Log√≠stica.
    > 

### üìå Conclusi√≥n General

- El modelo de **Random Forest** se destac√≥ por sus **m√©tricas muy buenas**, y aunque no ofreci√≥ predicciones extremas, su resultado sugiere **una clasificaci√≥n confiable** sin falsos positivos notables, aunque tiene **cierta indecisi√≥n al clasificar**.
- La **Red con Keras** mostr√≥ ser poco √∫til para el problema en cuesti√≥n debido a su bajo rendimiento general, a pesar de algunas predicciones alarmantes.
- La **Red Manual** se comport√≥ de forma **coherente con la distribuci√≥n real de clases (conforme al dataset del cual se entrenaron los modelos)**, indicando una capacidad de generalizaci√≥n s√≥lida frente al nuevo dataset.
- **XGBoost y Regresi√≥n Log√≠stica**: Aunque conservadores, son consistentes entre s√≠, adem√°s de presentar **muy buenas m√©tricas** (sobre todo **XGBoost**). Su similitud en la distribuci√≥n refuerza la validez de sus predicciones.

# üìÑ Streamlit

---

## üîπ Descripci√≥n general

La aplicaci√≥n fue desarrollada en Python usando **Streamlit** para construir una interfaz web interactiva que permite detectar transacciones fraudulentas en la red Ethereum.

Emplea **m√∫ltiples modelos de machine y deep learning previamente entrenados y serializados** para emitir una predicci√≥n confiable y explicable. La consulta de datos se realiza a trav√©s de la API de **Alchemy**, y los resultados se presentan con visualizaciones claras e informes descargables.

---

## üîπ Objetivo

Permitir al usuario cargar una transacci√≥n espec√≠fica (por su `hash`) o consultar un conjunto reciente de transacciones, y obtener un diagn√≥stico autom√°tico sobre si es **fraude o no**, respaldado por:

- Predicciones de varios modelos.
- Gr√°ficos de probabilidad.
- Estad√≠sticas clave.
- Un informe descargable con lo anterior mencionado.

---

## üîπ Modelos utilizados

Se utilizan **cinco modelos** de machine learning y deep learning previamente entrenados sobre un dataset etiquetado. 

- üß† **Red neuronal manual (con propagaci√≥n hacia adelante)**
- ü§ñ **Red Kera**
- üå≤ **Random Forest**
- üìà **Regresi√≥n log√≠stica con Balanced Bagging**
- ‚ö° **XGBoost con Balanced Bagging**

Cada modelo predice una probabilidad de que la transacci√≥n sea fraudulenta.

üì¶ **Carga de modelos**

En el backend, se utiliza c√≥digo como este:

### **`cargar_modelo(nombre_modelo)`**

```python

def cargar_modelo(nombre_modelo):
    return joblib.load(f'../models/{nombre_modelo}')
```

- Carga los modelos previamente entrenados desde el directorio `../models/`.

---

## üîπ Flujo de uso

### üü¢ Ingreso de datos

El usuario puede:

1. Ingresar un `hash` de transacci√≥n de Ethereum.
2. Consultar un conjunto hist√≥rico de transacciones configurando:
    - ‚è±Ô∏è Tiempo hacia atr√°s (en minutos).
    - üìä Cantidad m√°xima de transacciones.

### üîç Consulta de datos (Alchemy)

Se consulta la API de **Alchemy** para obtener las caracter√≠sticas de la transacci√≥n o del conjunto.

Se usa una funci√≥n como esta para obtener los datos

```python
load_dotenv(dotenv_path=os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), ".env"))
api_key = os.getenv("ALCHEMY_API_KEY")
if not api_key:
    raise ValueError("‚ö†Ô∏è API_KEY no est√° definida en las variables de entorno")
ALCHEMY_URL = f"https://eth-mainnet.g.alchemy.com/v2/{api_key}"
```

Se usa una funci√≥n como esta para obtener los datos:

---

### üß† Predicci√≥n m√∫ltiple

Cada modelo recibe los mismos datos y devuelve una probabilidad de fraude (entre 0 y 1).

### **`predecir_modelo(...)`**

```python
python
CopiarEditar
def predecir_modelo(modelo, X, nombre_modelo, scaler=None):
    ...
```

Esta es la funci√≥n m√°s importante y se adapta seg√∫n el tipo de modelo.

### **Par√°metros:**

- `modelo`: el modelo cargado (Keras, red neuronal manual, XGBoost, etc.).
- `X`: los datos de entrada para predecir.
- `nombre_modelo`: string que indica qu√© tipo de modelo es.
- `scaler`: objeto de escalado (puede ser `None`).

### **L√≥gica:**

1. Aplica el scaler si existe.
2. Seg√∫n el tipo de modelo (`nombre_modelo`), predice probabilidades y clases:
    - **Keras**:
        - Usa `.predict`.
        - Usa `argmax` para clase y `[:, 1]` para probabilidad de fraude.
    - **Red neuronal manual**:
        - Usa matrices `W1`, `b1`, `W2`, `b2`, y funciones `FunH`, `FunO`.
        - Calcula **propagaci√≥n hacia adelante** manualmente.
        - Usa `evaluar(Fun, neta)` para aplicar funciones de activaci√≥n.
        - Imprime diagn√≥stico de predicciones.
    - **XGBoost**:
        - Usa `predict_proba` y decide clase con umbral 0.5.
        - Tambi√©n imprime info diagn√≥stica.
    - **Otros modelos (Random Forest, Logistic, etc.)**:
        - Usa `predict` y `predict_proba` de `sklearn`.

### **Devuelve:**

```python
return y_pred, y_pred_proba, tiempo_ejecucion
```

- `y_pred`: clase predicha (0 = no fraude, 1 = fraude).
- `y_pred_proba`: probabilidad de fraude.
- `tiempo_ejecucion`: cu√°nto tard√≥ la predicci√≥n.

---

### ‚öñÔ∏è Decisi√≥n final

Si **2 o m√°s modelos** predicen una probabilidad > 0.75, se considera que la transacci√≥n es fraudulenta.

```python
CopiarEditar
if sum(prob > 0.75 for prob in probabilidades_modelos) >= 2:
    resultado = "‚ùå Fraude"
else:
    resultado = "‚úÖ No fraude"
```

---

### üì∫ Visualizaci√≥n del resultado

En la interfaz se muestra:

- Etiqueta final: "‚úÖ No fraude" o "‚ùå Fraude"

---

## üìÑ Informe descargable

El usuario puede generar un informe PDF que incluye:

- Histograma de probabilidades por modelo
- M√©tricas de cada modelo (F1-score, precisi√≥n, recall, etc.)
- Fecha de consulta y hash analizado

---

## üß† Ventajas del enfoque

- ‚úÖ **Multimodelo**: robustez frente a errores individuales
- ‚úÖ **Explicabilidad**: visualizaciones claras e informes detallados
- ‚úÖ **Simplicidad**: basta con un `hash` o un par√°metro de tiempo para una serie de transacciones
- ‚úÖ **Modularidad**: f√°cil de extender con m√°s modelos o mejoras en la interfaz


# ‚úÖ Conclusiones Finales

El presente proyecto logr√≥ desarrollar un sistema efectivo para la **detecci√≥n autom√°tica de transacciones fraudulentas en la red de Ethereum**, combinando t√©cnicas cl√°sicas y modernas de aprendizaje autom√°tico. A trav√©s del an√°lisis, preprocesamiento y modelado de datos hist√≥ricos, se construy√≥ una base s√≥lida para abordar un problema real con alto impacto en la comunidad cripto.

A lo largo del proceso se cumpli√≥ con cada uno de los objetivos propuestos:

- Se realiz√≥ un **an√°lisis exploratorio exhaustivo** que permiti√≥ entender mejor el comportamiento de las transacciones y preparar adecuadamente el dataset.
- Se entrenaron y compararon **cinco modelos de clasificaci√≥n**, incluyendo algoritmos cl√°sicos como Regresi√≥n Log√≠stica y Random Forest, as√≠ como modelos de redes neuronales profundas.
- La evaluaci√≥n de los modelos se llev√≥ a cabo mediante m√©tricas como accuracy, precisi√≥n, recall y F1-score, permitiendo una **comparaci√≥n objetiva del rendimiento**.
- La mayor√≠a de los modelos se destacaron como robustos y confiables, tanto en el conjunto de validaci√≥n como frente a nuevos datos externos.
- Se implement√≥ un sistema de consulta en **tiempo real a trav√©s de la API de Alchemy**, integrando estos datos al pipeline de predicci√≥n tras una estandarizaci√≥n adecuada.
- Finalmente, se desarroll√≥ una **aplicaci√≥n web con Streamlit**, que permite a los usuarios finales consultar cualquier transacci√≥n y predecir su legitimidad de forma accesible e interactiva.

El sistema resultante constituye una **herramienta pr√°ctica, modular y reutilizable**, adaptable a futuras mejoras tanto en el volumen de datos como en la arquitectura de los modelos. Adem√°s, al estar disponible en GitHub, el proyecto fomenta la **colaboraci√≥n abierta y el uso responsable de la inteligencia artificial en entornos financieros**.

Este trabajo no solo demuestra la viabilidad de aplicar machine learning al monitoreo de redes blockchain, sino que tambi√©n sienta las bases para **mejoras futuras en la prevenci√≥n de fraudes**, con la posibilidad de incorporar t√©cnicas m√°s avanzadas como detecci√≥n de anomal√≠as, aprendizaje semi-supervisado o integraci√≥n de modelos de grafos.