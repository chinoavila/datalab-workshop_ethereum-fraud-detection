# ğŸ§¾ Resumen

El proyecto comenzÃ³ con el anÃ¡lisis de un conjunto de datos de transacciones en Ethereum, el cual presentaba un fuerte desbalance entre transacciones legÃ­timas y fraudulentas. Se llevÃ³ a cabo un anÃ¡lisis exploratorio de datos (EDA) y una limpieza del dataset, evaluando diferentes estrategias de balanceo como SMOTE. A partir de esta base, se entrenaron y compararon una serie de modelos: una red neuronal implementada desde cero, una red utilizando la librerÃ­a Keras, un modelo clÃ¡sico de Random Forest, un modelo de regresiÃ³n logÃ­stica y un modelo XGBoost. SegÃºn las mÃ©tricas de evaluaciÃ³n (precisiÃ³n, recall, F1-score), Random Forest y XGBoost resultaron ser los modelos mÃ¡s efectivos, alcanzando una alta capacidad de detecciÃ³n. Una vez validado los modelos, se desarrollÃ³ un pipeline para obtener datos en tiempo real desde la API de Alchemy y clasificar nuevas transacciones automÃ¡ticamente. Todo el desarrollo fue subido a un repositorio pÃºblico en GitHub, y como cierre del proyecto se implementÃ³ una aplicaciÃ³n web utilizando Streamlit. En esta app, los usuarios pueden ingresar un hash de transacciÃ³n y seleccionar el modelo con el que desean clasificarla. De este modo, se integran todos los componentes del proyecto â€”desde el anÃ¡lisis de datos hasta la interfaz de usuarioâ€” en una soluciÃ³n funcional y accesible.


# ğŸ§¾IntroducciÃ³n

En el contexto actual del crecimiento exponencial de las criptomonedas, Ethereum se ha consolidado como una de las plataformas blockchain mÃ¡s utilizadas a nivel global. Sin embargo, junto con su popularidad tambiÃ©n han aumentado las actividades fraudulentas en su red, como transacciones falsas, esquemas de phishing y otros tipos de estafas. Detectar este tipo de comportamiento en tiempo real es fundamental para proteger a los usuarios y mantener la integridad del ecosistema.

### ğŸ¯ Objetivo general

Desarrollar un sistema capaz de detectar automÃ¡ticamente transacciones fraudulentas en la red de Ethereum utilizando tÃ©cnicas de aprendizaje automÃ¡tico y aprendizaje profundo.

âœ… **Objetivos especÃ­ficos**

- Analizar y procesar un conjunto de datos reales de transacciones en Ethereum.
- Aplicar un anÃ¡lisis exploratorio de datos (EDA) que permita comprender el comportamiento del conjunto y realizar una limpieza adecuada.
- Explorar y comparar distintos modelos de clasificaciÃ³n, incluyendo redes neuronales, modelos construidos desde cero y modelos clÃ¡sicos como Random Forest o RegresiÃ³n logÃ­stica.
- Evaluar el desempeÃ±o de los modelos mediante mÃ©tricas estÃ¡ndar (accuracy, precision, recall, F1-score).
- Seleccionar el o los modelos con mejor rendimiento, aplicando sobre Ã©l o ellos una validaciÃ³n interna y un proceso de optimizaciÃ³n de hiperparÃ¡metros.
- Obtener datos en tiempo real desde la API de Alchemy y preprocesarlos para que tengan la misma estructura y atributos que el dataset de entrenamiento.
- Aplicar el o los modelos entrenados, validados y optimizados a los datos externos para clasificar nuevas transacciones como fraudulentas o legÃ­timas.
- Subir todos los modelos, scripts de procesamiento, EDA, consultas a la API a un repositorio pÃºblico de GitHub para su disponibilidad y reutilizaciÃ³n.
- Desarrollar una aplicaciÃ³n web interactiva mediante Streamlit, donde los usuarios puedan consultar cualquier transacciÃ³n en la red y seleccionar el modelo con el que desean hacer la predicciÃ³n (aunque se recomienda el uso del modelo Random Forest por su mayor desempeÃ±o).

ğŸ§  **JustificaciÃ³n del uso de redes neuronales**

El uso de redes neuronales se justifica por su capacidad para modelar patrones complejos y no lineales en grandes volÃºmenes de datos, como ocurre en las transacciones blockchain. A diferencia de los modelos clÃ¡sicos, las redes neuronales pueden captar relaciones sutiles entre mÃºltiples variables que pueden pasar desapercibidas en otros enfoques. Este tipo de modelos ha demostrado un desempeÃ±o superior en tareas de detecciÃ³n de anomalÃ­as y clasificaciÃ³n de eventos raros, como el fraude en redes descentralizadas. Por esta razÃ³n, el trabajo no solo implementa modelos tradicionales, sino que tambiÃ©n explora el potencial de redes neuronales desarrolladas desde cero y a travÃ©s de frameworks como Keras.


# ğŸ“Š ExploraciÃ³n y anÃ¡lisis de datos (EDA)

## ğŸ“Œ DescripciÃ³n general del dataset

Cada fila representa una **cuenta Ãºnica de Ethereum**, con estadÃ­sticas agregadas sobre su comportamiento en transacciones y uso de tokens.

El dataset original cuenta con **51 columnas**, incluyendo la variable objetivo `FLAG`, que indica si una cuenta estÃ¡ asociada a actividad fraudulenta (`1`) o no (`0`). El dataset estÃ¡ **desbalanceado**, con una menor proporciÃ³n de cuentas fraudulentas.

## ğŸ§· Significado de las columnas

| **Nombre de columna** | **DescripciÃ³n** |
| --- | --- |
| `Address` | DirecciÃ³n de la cuenta de Ethereum. |
| `FLAG` | Indica si la cuenta es fraudulenta (1) o no (0). |
| `Avg min between sent tnx` | Tiempo promedio entre transacciones enviadas (en minutos). |
| `Avg_min_between_received_tnx` | Tiempo promedio entre transacciones recibidas (en minutos). |
| `Time_Diff_between_first_and_last(Mins)` | Tiempo total entre la primera y Ãºltima transacciÃ³n (en minutos). |
| `Sent_tnx` | Total de transacciones normales enviadas. |
| `Received_tnx` | Total de transacciones normales recibidas. |
| `Number_of_Created_Contracts` | Total de contratos creados por la cuenta. |
| `Unique_Received_From_Addresses` | NÃºmero de direcciones Ãºnicas desde las que se recibiÃ³ Ether. |
| `Unique_Sent_To_Addresses20` | NÃºmero de direcciones Ãºnicas a las que se enviÃ³ Ether. |
| `Min_Value_Received` | Valor mÃ­nimo de Ether recibido. |
| `Max_Value_Received` | Valor mÃ¡ximo de Ether recibido. |
| `Avg_Value_Received` | Valor promedio de Ether recibido. |
| `Min_Val_Sent` | Valor mÃ­nimo de Ether enviado. |
| `Max_Val_Sent` | Valor mÃ¡ximo de Ether enviado. |
| `Avg_Val_Sent` | Valor promedio de Ether enviado. |
| `Min_Value_Sent_To_Contract` | Valor mÃ­nimo enviado a contratos. |
| `Max_Value_Sent_To_Contract` | Valor mÃ¡ximo enviado a contratos. |
| `Avg_Value_Sent_To_Contract` | Valor promedio enviado a contratos. |
| `Total_Transactions(Including_Tnx_to_Create_Contract)` | Total de transacciones, incluidas las de creaciÃ³n de contratos. |
| `Total_Ether_Sent` | Total de Ether enviado. |
| `Total_Ether_Received` | Total de Ether recibido. |
| `Total_Ether_Sent_Contracts` | Total de Ether enviado a contratos. |
| `Total_Ether_Balance` | Saldo final de Ether. |
| `Total_ERC20_Tnxs` | Total de transacciones de tokens ERC20. |
| `ERC20_Total_Ether_Received` | Total recibido en transacciones de tokens ERC20. |
| `ERC20_Total_Ether_Sent` | Total enviado en transacciones de tokens ERC20. |
| `ERC20_Total_Ether_Sent_Contract` | Total enviado a contratos en tokens ERC20. |
| `ERC20_Uniq_Sent_Addr` | Total de direcciones Ãºnicas a las que se enviaron tokens ERC20. |
| `ERC20_Uniq_Rec_Addr` | Total de direcciones Ãºnicas desde las que se recibieron tokens ERC20. |
| `ERC20_Uniq_Rec_Contract_Addr` | Total de contratos Ãºnicos desde los que se recibieron tokens ERC20. |
| `ERC20_Avg_Time_Between_Sent_Tnx` | Tiempo promedio entre envÃ­os de tokens ERC20. |
| `ERC20_Avg_Time_Between_Rec_Tnx` | Tiempo promedio entre recepciones de tokens ERC20. |
| `ERC20_Avg_Time_Between_Contract_Tnx` | Tiempo promedio entre transacciones hacia contratos en tokens ERC20. |
| `ERC20_Min_Val_Rec` | Valor mÃ­nimo recibido en transacciones ERC20. |
| `ERC20_Max_Val_Rec` | Valor mÃ¡ximo recibido en transacciones ERC20. |
| `ERC20_Avg_Val_Rec` | Valor promedio recibido en transacciones ERC20. |
| `ERC20_Min_Val_Sent` | Valor mÃ­nimo enviado en transacciones ERC20. |
| `ERC20_Max_Val_Sent` | Valor mÃ¡ximo enviado en transacciones ERC20. |
| `ERC20_Avg_Val_Sent` | Valor promedio enviado en transacciones ERC20. |
| `ERC20_Uniq_Sent_Token_Name` | NÃºmero de tipos Ãºnicos de tokens enviados. |
| `ERC20_Uniq_Rec_Token_Name` | NÃºmero de tipos Ãºnicos de tokens recibidos. |
| `ERC20_Most_Sent_Token_Type` | Tipo de token mÃ¡s enviado. |
| `ERC20_Most_Rec_Token_Type` | Tipo de token mÃ¡s recibido. |

## ğŸ§ª AnÃ¡lisis exploratorio inicial

### ğŸ”¹ InspecciÃ³n general: `.info()`

Se identificÃ³ que muchas columnas, especialmente de la 26 en adelante (relacionadas con tokens ERC20), contienen **valores nulos**.

- Las Ãºltimas columnas, como `ERC20_Most_Sent_Token_Type` y `ERC20_Most_Rec_Token_Type`, son categÃ³ricas con **alto porcentaje de nulos** y fueron eliminadas del anÃ¡lisis.
- Los **valores nulos en variables numÃ©ricas** se imputaron con la media.

### ğŸ” CorrelaciÃ³n cruzada entre `FLAG` y el resto de las variables

Se llevÃ³ a cabo una **correlaciÃ³n cruzada entre la variable `FLAG`** (indicador de fraude) y todas las demÃ¡s columnas del dataset. El objetivo era determinar quÃ© tan relacionadas estÃ¡n las caracterÃ­sticas disponibles con la etiqueta de clasificaciÃ³n.

### ğŸ“Š Resultado:

- Todas las correlaciones cruzadas obtenidas entre `FLAG` y las demÃ¡s variables arrojaron **valores absolutos menores a 0.1**.
- Esto indica una **muy baja relaciÃ³n lineal directa o inversa** con la variable objetivo.

### ğŸ“Œ Implicancias:

- La ausencia de una correlaciÃ³n fuerte sugiere que **no hay atributos individuales que por sÃ­ solos expliquen el fraude de manera lineal**.
- Este hallazgo **no implica que las variables sean inÃºtiles**, sino que **las relaciones relevantes pueden ser no lineales o depender de interacciones complejas**.

## ğŸ§¹ Limpieza y reducciÃ³n del dataset

### ğŸ”¸ Columnas con valores constantes (solo ceros)

Se eliminaron 7 columnas que contenÃ­an exclusivamente valores 0:

- `ERC20 avg time between sent tnx`
- `ERC20 avg time between rec tnx`
- `ERC20 avg time between rec 2 tnx`
- `ERC20 avg time between contract tnx`
- `ERC20 min val sent contract`
- `ERC20 max val sent contract`
- `ERC20 avg val sent contract`

Estas columnas **no aportan varianza ni informaciÃ³n Ãºtil al modelo**.

### ğŸ”¸ Columnas irrelevantes

Se eliminaron ademÃ¡s:

- `Unnamed: 0`
- `Index`

por ser simplemente Ã­ndices sin valor predictivo.

### ğŸ”¸ EliminaciÃ³n de columnas altamente correlacionadas

Se construyÃ³ una matriz de correlaciÃ³n y se eliminaron los siguientes pares redundantes (corr â‰¥ 0.99):

| Par de columnas altamente correlacionadas | Columna eliminada |
| --- | --- |
| `max val sent to contract` â€” `total ether sent contracts` | `max val sent to contract` |
| `ERC20 total Ether received` â€” `ERC20 max val rec` | `ERC20 total Ether received` |
| `ERC20 max val sent` â€” `ERC20 avg val sent` | `ERC20 max val sent` |
| `ERC20 min val sent` â€” `ERC20 avg val sent` | `ERC20 min val sent` |
| `ERC20 total ether sent` â€” `ERC20 max val sent` | `ERC20 total ether sent` |
| `ERC20 uniq rec contract addr` â€” `ERC20 uniq rec token name` | `ERC20 uniq rec token name` |
| `ERC20 total ether sent` â€” `ERC20 avg val sent` | â€” (ya eliminada arriba) |

Estas columnas fueron eliminadas para reducir la **multicolinealidad** y simplificar el modelo.

![Matriz de correlaciÃ³n](img/correlaciÃ³n.png)


## ğŸ“Š AnÃ¡lisis de balance y visualizaciÃ³n

### Conteo de la variable `FLAG`:

âœ… **Resultados:**

- **Cuentas legÃ­timas (0):** 7662 (â‰ˆ77.86%)
- **Cuentas fraudulentas (1):** 2179 (â‰ˆ22.14%)

![Histograma de fraudes o no fraudes](img/Histograma.png)

Se confirma un **fuerte desbalance** de clases. Esto serÃ¡ considerado durante el modelado (ponderaciÃ³n, muestreo o mÃ©tricas apropiadas).

## ğŸ“ Resultado final

Tras el preprocesamiento:

- Se pasÃ³ de **51 a 33 columnas**.
- Se conservaron Ãºnicamente **columnas numÃ©ricas relevantes**.
- El dataset quedÃ³ listo para aplicar modelos de clasificaciÃ³n, con menor redundancia y mayor calidad.

### âœ… Recomendaciones:

- Utilizar modelos capaces de capturar relaciones **no lineales y multidimensionales**, como:
    - Random Forest, Gradient Boosting, XGBoost.
    - Redes neuronales (MLP).


# Modelos:

## ğŸ§  Modelo de Red Neuronal

### ğŸ¯ Objetivo

Este modelo de red neuronal fue desarrollado para detectar fraudes en transacciones financieras. El modelo fue entrenado utilizando un conjunto de datos desbalanceado (`transaction_dataset_clean.csv`), y se implementaron tÃ©cnicas de preprocesamiento, normalizaciÃ³n y ajuste de hiperparÃ¡metros. Se evaluaron dos enfoques: sin oversampling y con oversampling (SMOTE) para la mejora del rendimiento en la clase minoritaria (fraude).

 

### ğŸ“¦ LibrerÃ­as utilizadas

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report
from imblearn.over_sampling import SMOTE
```

### ğŸ§¾ **CaracterÃ­sticas del Modelo:**

- **Arquitectura de la Red Neuronal:**
    - Entrada: 32 neuronas
    - Ocultas: 20 neuronas
    - Salida: 2 neuronas
- **Activaciones:**
    - 'sigmoid' y 'tanh'
- **MÃ©todo de Entrenamiento:**
    - **Algoritmo:** Backpropagation con descenso del gradiente
    - **Aprendizaje EstocÃ¡stico**
    - **Criterio de Parada:** Convergencia del error
- **MÃ©tricas Evaluadas:**
    - PrecisiÃ³n
    - Recall
    - F1-Score
    - Accuracy
    - Matriz de confusiÃ³n

### âš™ï¸ Preprocesamiento

- DivisiÃ³n en conjunto de entrenamiento y test (70/30).
- **NormalizaciÃ³n** por media y desvÃ­o estÃ¡ndar usando `StandardScaler`.
- **One-hot encoding** aplicado a la variable objetivo.
- CodificaciÃ³n de la salida en el rango `[-1, 1]` para adaptarse a `tanh`.

> Se probÃ³ tambiÃ©n usar SMOTE para balancear las clases en el entrenamiento.
> 

---

### ğŸ“Š **Resultados Sin Oversampling:**

### **Matriz de ConfusiÃ³n (Test) y MÃ©tricas:**

```

[[2243   60]
 [  66  584]]

```

| Clase | Precision | Recall | F1-Score | Support |
| --- | --- | --- | --- | --- |
| **0** | 0.97 | 0.97 | 0.97 | 2303 |
| **1** | 0.91 | 0.90 | 0.90 | 650 |
| **Accuracy** |  |  | **0.96** | 2953 |
| **Macro Avg** | 0.94 | 0.94 | 0.94 | 2953 |
| **Weighted Avg** | 0.96 | 0.96 | 0.96 | 2953 |

### **AnÃ¡lisis:**

- **GeneralizaciÃ³n:** La pequeÃ±a diferencia entre accuracy de entrenamiento (96.6%) y prueba (95.7%) sugiere que el modelo no estÃ¡ sobreajustado ni subajustado.
- **DesempeÃ±o en la clase 0 (no fraude):** Muy buen desempeÃ±o en esta clase debido a la mayor cantidad de ejemplos.
- **DesempeÃ±o en la clase 1 (fraude):** Aunque el recall es de 90%, hay margen para mejorar en la detecciÃ³n de fraudes (falsos negativos).

---

### ğŸ“Š **Resultados con Oversampling (SMOTE):**

### **MÃ©tricas Clave:**

- **Accuracy:** Entre 45% y 60% (bajo rendimiento).
- **Clase 1 (fraude):**
    - **Recall:** 0.99 (el modelo detecta casi todos los fraudes).
    - **Precision:** Muy baja, debido a un alto nÃºmero de falsos positivos.
- **MÃ©tricas Generales:**
    - **Precision, Recall y F1-Score:** En orden similar al accuracy, con una disminuciÃ³n general del desempeÃ±o.

### **AnÃ¡lisis:**

- **DesempeÃ±o del Oversampling:** El modelo con SMOTE presenta un alto recall para la clase 1, pero este se logra a costa de muchos falsos positivos, lo que disminuye significativamente la precisiÃ³n y el accuracy global.
- **Posible Causa:** El uso de SMOTE podrÃ­a haber introducido datos sintÃ©ticos que no representan bien la distribuciÃ³n real de la clase minoritaria (fraude), lo que afecta la generalizaciÃ³n del modelo.

---

### ğŸŸ¢ **Conclusiones:**

- **Modelo Sin Oversampling:**
    - El modelo tiene un excelente desempeÃ±o, con un buen balance entre precisiÃ³n y recall, especialmente para la clase 0 (no fraude). El modelo detecta el 90% de los fraudes, lo que es un desempeÃ±o sÃ³lido.
- **Modelo con Oversampling:**
    - El modelo con oversampling presenta un buen recall en la clase 1 (fraude), pero el modelo genera demasiados falsos positivos, afectando gravemente la precisiÃ³n y el accuracy general.

### ğŸ“Œ ConclusiÃ³n final

- El modelo sin oversampling es mÃ¡s robusto y tiene un mejor rendimiento general, con un pequeÃ±o ajuste en el recall de la clase 1 se podrÃ­a mejorar la detecciÃ³n de fraudes. El modelo con oversampling no se recomienda usarlo (al menos no en este tipo de problemas), ya que distorsiona la realidad, es decir, es natural que haya mÃ¡s no fraudes que fraudes, por lo que al generar datos sintÃ©ticos se estarÃ­a â€œcontaminandoâ€ el dataset.


## ğŸ¤– Modelo de Red Neuronal con Keras

### ğŸ¯ Objetivo

Probar un modelo de red neuronal usando Keras sobre el dataset limpio (`transaction_dataset_clean.csv`) y comparar sus resultados con el modelo desarrollado a mano anteriormente.

---

### ğŸ“¦ LibrerÃ­as utilizadas

```python

import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

```

---

### ğŸ§¾ Estructura del modelo

- **Entradas:** 32 atributos (features)
- **Capa oculta:** 1 capa con 20 neuronas, activaciÃ³n `sigmoid`
- **Capa de salida:** 2 neuronas, activaciÃ³n `tanh`
- **OptimizaciÃ³n:** `SGD`
- **FunciÃ³n de pÃ©rdida:** `mean_squared_error`
- **MÃ©tricas:** Accuracy, Precision, Recall, F1-score

---

### âš™ï¸ Preprocesamiento

- DivisiÃ³n en conjunto de entrenamiento y test (70/30).
- **NormalizaciÃ³n** por media y desvÃ­o estÃ¡ndar usando `StandardScaler`.
- **One-hot encoding** aplicado a la variable objetivo.
- CodificaciÃ³n de la salida en el rango `[-1, 1]` para adaptarse a `tanh`.

> Se probÃ³ tambiÃ©n usar SMOTE para balancear las clases en el entrenamiento.
> 

---

### ğŸ“Š Resultados sin SMOTE

**Matriz de confusiÃ³n (Test):**

```

[[2277   26]
 [ 363  287]]

```

**Reporte de clasificaciÃ³n:**

| Clase | Precision | Recall | F1-score | Soporte |
| --- | --- | --- | --- | --- |
| 0 | 0.86 | 0.99 | 0.92 | 2303 |
| 1 | 0.91 | 0.44 | 0.59 | 650 |
- **Accuracy:** 0.87
- **Macro avg F1:** 0.76
- **Weighted avg F1:** 0.85

ğŸ”´ **ConclusiÃ³n sin SMOTE:**

El modelo no logra buenos resultados para la clase 1 (fraude). Predice bien la clase mayoritaria, pero falla mucho en la minoritaria: mÃ¡s de la mitad de los fraudes no se detectan. Aunque el accuracy es razonable, no refleja el verdadero desempeÃ±o debido al desbalance de clases.

---

### ğŸ“Š Resultados con SMOTE

**Matriz de confusiÃ³n (Test):**

```
lua
CopiarEditar
[[1891  412]
 [  76  574]]

```

**Reporte de clasificaciÃ³n:**

| Clase | Precision | Recall | F1-score | Soporte |
| --- | --- | --- | --- | --- |
| 0 | 0.96 | 0.82 | 0.89 | 2303 |
| 1 | 0.58 | 0.88 | 0.70 | 650 |
- **Accuracy:** 0.83
- **Macro avg F1:** 0.79
- **Weighted avg F1:** 0.85

ğŸŸ¢ **ConclusiÃ³n con SMOTE:**

El modelo mejora sustancialmente en la detecciÃ³n de fraudes. El recall y el F1-score de la clase 1 aumentan considerablemente, lo cual es clave en este tipo de problemas. Aunque el accuracy general baja, el modelo es mÃ¡s justo y Ãºtil para el propÃ³sito del anÃ¡lisis.

---

### ğŸ“Œ Conclusiones generales

- Se probÃ³ una arquitectura muy similar a la red neuronal desarrollada a mano.
- Los resultados sin tÃ©cnicas de balanceo no fueron buenos para la clase 1.
- SMOTE mejorÃ³ considerablemente la detecciÃ³n de fraudes, sin embargo, hay que tener en cuenta que al generar datos sintÃ©ticos no se estÃ¡ reflejando la realidad del problema, es decir, es natural que haya menos fraudes que no fraudes. Por lo que con tÃ©cnicas de oversampling se estarÃ­a â€œcontaminandoâ€ el dataset, ademÃ¡s los resultados tampoco fueron muy buenos en comparaciÃ³n con el modelo de red neuronal desarrollado anteriormente.


## ğŸŒ² Modelo Random Forest

### ğŸ¯ Objetivo

Probar un modelo clÃ¡sico de machine learning usando Random Forest sobre el dataset limpio (`transaction_dataset_clean.csv`) y comparar sus resultados con los modelos desarrollados anteriormente.

### ğŸ“¦ LibrerÃ­as utilizadas

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier                                      
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc      
from sklearn.model_selection import train_test_split, RandomizedSearchCV             
import matplotlib.pyplot as plt

```

### ğŸ§ª Desarrollo del modelo

### 1. **PreparaciÃ³n de los datos**

- Se utilizÃ³ el dataset limpio con el que se venÃ­a trabajando.
- Se separÃ³ la variable objetivo `'FLAG'` del resto de los predictores.
- Se aplicÃ³ una divisiÃ³n **estratificada** del dataset:
    - 70% para entrenamiento
    - 15% para validaciÃ³n
    - 15% para test

```python

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)

```

### 2. **NormalizaciÃ³n**

- Se normalizaron los datos con `StandardScaler`, ajustando solo sobre el conjunto de entrenamiento y transformando el resto.

```python

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

```

### 3. **Entrenamiento inicial**

- Se entrenÃ³ un primer modelo base de `RandomForestClassifier` con 100 Ã¡rboles para evaluar desempeÃ±o preliminar.
- MÃ©tricas mostraron un rendimiento alto desde el inicio.

### 4. **OptimizaciÃ³n de hiperparÃ¡metros**

- Se utilizÃ³ `RandomizedSearchCV` para encontrar la mejor combinaciÃ³n de hiperparÃ¡metros con `class_weight='balanced'`.
- Se usÃ³ validaciÃ³n cruzada con 5 folds sobre el conjunto de **validaciÃ³n**, no sobre el de entrenamiento, para evitar sobreajuste.

```python

random_search = RandomizedSearchCV(
    estimator=RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1),
    param_distributions=param_grid,
    n_iter=20,
    cv=5,
    verbose=2,
    random_state=42,
    n_jobs=-1
)
random_search.fit(X_val, y_val)
```

### 5. **EvaluaciÃ³n del modelo optimizado**

- Se reentrenÃ³ el modelo con los **mejores hiperparÃ¡metros** encontrados sobre el conjunto de entrenamiento.
- Se evaluÃ³ el desempeÃ±o en el conjunto de test.

```python

rf_opt = RandomForestClassifier(**mejores_params, class_weight='balanced', random_state=42, n_jobs=-1)
rf_opt.fit(X_train, y_train)
y_test_pred = rf_opt.predict(X_test)

```

---

### ğŸ“ˆ Resultados en conjunto de test

**Matriz de confusiÃ³n:**

```

[[1146    4]
 [  21  306]]

```

**Reporte de clasificaciÃ³n:**

| Clase | Precision | Recall | F1-Score | Soporte |
| --- | --- | --- | --- | --- |
| 0 (no fraude) | 0.98 | 1.00 | 0.99 | 1150 |
| 1 (fraude) | 0.99 | 0.94 | 0.96 | 327 |
| **Accuracy global** |  |  | **0.98** | 1477 |

---

### ğŸ“Œ AnÃ¡lisis y JustificaciÃ³n

### Â¿El modelo puede mejorar mÃ¡s?

El modelo alcanza un desempeÃ±o excelente, sobre todo en la clase minoritaria (fraude):

- **PrecisiÃ³n: 0.99** â†’ casi ningÃºn falso positivo.
- **Recall: 0.94** â†’ detecta 94% de los fraudes.
- **F1-score: 0.96** â†’ excelente equilibrio entre precisiÃ³n y recall.

### Â¿Aplicar SMOTE?

Se decidiÃ³ **no aplicar tÃ©cnicas como SMOTE**, por los siguientes motivos:

- El modelo ya detecta fraudes con alto rendimiento.
- Generar fraudes sintÃ©ticos **distorsionarÃ­a la distribuciÃ³n real del problema**, que es naturalmente desbalanceada.
- Es preferible que el modelo aprenda en el contexto realista, donde el fraude ocurre 1 de cada 5 veces o menos.

### Â¿Bajar el umbral de decisiÃ³n?

TambiÃ©n se decidiÃ³ **no modificar el umbral predeterminado (0.5)**:

- Bajar el umbral podrÃ­a aumentar el recall, pero **a costa de muchos mÃ¡s falsos positivos**, lo que no es aceptable en este contexto.
- Dado el balance actual entre precisiÃ³n y recall, **el valor por defecto del umbral es razonable**.
- Incluso se considerÃ³ que **subir** el umbral podrÃ­a tener mÃ¡s sentido si se buscara aÃºn mÃ¡s certeza ante una predicciÃ³n de fraude.

---

### ğŸ“ ConclusiÃ³n

El modelo ha sido optimizado correctamente, alcanzando mÃ©tricas sobresalientes en un problema desbalanceado. Se considera que **ya llegÃ³ a su lÃ­mite razonable de mejora**, y se justifica **no aplicar tÃ©cnicas adicionales como SMOTE ni modificar el umbral de clasificaciÃ³n**.

El modelo es robusto, eficiente y confiable para detectar fraudes con alta precisiÃ³n sin comprometer la tasa de falsos positivos.

## ğŸ“ˆ Modelo RegresiÃ³n LogÃ­stica

### ğŸ“‹ Objetivo

El objetivo de este modelo fue detectar transacciones fraudulentas utilizando un enfoque supervisado de clasificaciÃ³n binaria mediante regresiÃ³n logÃ­stica. Se aplicaron distintas estrategias para abordar el problema del desbalance de clases.

---

### ğŸ§ª Dataset

- Se utilizÃ³ un dataset de transacciones (`transaction_dataset_clean.csv`) donde la variable objetivo es `FLAG` (0: Sin fraude, 1: Con fraude).
- Se aplicaron transformaciones con `get_dummies()` para convertir variables categÃ³ricas en variables numÃ©ricas.
- DivisiÃ³n de los datos:
    - Entrenamiento: 30%
    - Test: 70%

---

### âš™ï¸ Modelo base (sin balanceo)

- **Clasificador**: `LogisticRegression` (penalizaciÃ³n L2, solver: newton-cg)
- **MÃ©trica principal**: F1-score, especialmente para la clase minoritaria (fraude)

### Resultados:

| Clase | PrecisiÃ³n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.85 | 1.00 | 0.92 |
| Con fraude | 0.99 | 0.37 | 0.54 |
| **Accuracy** | **0.86** |  |  |

ğŸ” **ObservaciÃ³n**: Alta precisiÃ³n pero baja recuperaciÃ³n de fraudes (recall 0.37), tÃ­pico en datasets desbalanceados.

---

### âš–ï¸ Estrategias de Balanceo

### ğŸ“ 1. PenalizaciÃ³n (`class_weight="balanced"`)

- Ajuste automÃ¡tico de pesos inversamente proporcionales a la frecuencia de las clases.

**Resultados:**

| Clase | PrecisiÃ³n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.88 | 0.98 | 0.93 |
| Con fraude | 0.90 | 0.53 | 0.67 |
| **Accuracy** | **0.88** |  |  |

âœ… **Mejora significativa del recall en la clase minoritaria.**

---

### ğŸ“ 2. Under-Sampling (NearMiss)

- ReducciÃ³n de la clase mayoritaria para igualar la cantidad de muestras.

**Resultados:**

| Clase | PrecisiÃ³n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.98 | 0.36 | 0.53 |
| Con fraude | 0.30 | 0.97 | 0.46 |
| **Accuracy** | **0.50** |  |  |

âš ï¸ **Muy bajo rendimiento general. Aunque mejora el recall de fraudes, baja mucho la precisiÃ³n.**

---

### ğŸ“ 3. Over-Sampling (RandomOverSampler)

- RÃ©plica de muestras de la clase minoritaria.

**Resultados:**

| Clase | PrecisiÃ³n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.88 | 0.98 | 0.93 |
| Con fraude | 0.87 | 0.54 | 0.67 |
| **Accuracy** | **0.88** |  |  |

âœ… **Resultados similares al caso de penalizaciÃ³n. Mejora sin afectar negativamente el modelo.**

---

### ğŸ“ 4. Ensamble Balanceado (BalancedBaggingClassifier)

- Uso de mÃºltiples modelos con muestreo balanceado interno.

**Resultados:**

| Clase | PrecisiÃ³n | Recall | F1-score |
| --- | --- | --- | --- |
| Sin fraude | 0.98 | 0.97 | 0.98 |
| Con fraude | 0.91 | 0.94 | 0.92 |
| **Accuracy** | **0.97** |  |  |

ğŸ† **Mejor estrategia de todas**: AltÃ­sima precisiÃ³n y recall para ambas clases.

---

### ğŸ“ˆ ConclusiÃ³n

- El modelo de regresiÃ³n logÃ­stica sin balancear **no es suficiente** para detectar fraudes de forma efectiva.
- Las estrategias de **penalizaciÃ³n** y **oversampling** logran mejoras considerables.
- La mejor performance se logrÃ³ con **BalancedBaggingClassifier**, obteniendo un excelente balance entre precisiÃ³n y recall.
- El tratamiento del desbalance de clases es **crucial** para problemas de detecciÃ³n de fraude.

## âš¡ Modelo XGBoost

### ğŸ“Œ Objetivo

El script entrena y evalÃºa un modelo de clasificaciÃ³n con distintos enfoques de balanceo de clases para detectar transacciones fraudulentas en un dataset desbalanceado.

---

### ğŸ§© Dependencias

- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `sklearn`: mÃ©tricas, split de datos
- `xgboost`
- `imblearn`: tÃ©cnicas de resampling y ensemble

---

### ğŸ§¶ Estructura del Script

### 1. **Carga de Datos**

Se carga un archivo CSV con datos de transacciones. Se imprime la dimensiÃ³n del dataset y la distribuciÃ³n de clases (`FLAG`: 0 = no fraude, 1 = fraude).

```python

df = pd.read_csv("../../datasets/transaction_dataset.csv")
```

### 2.**Preprocesamiento**

- Se eliminan columnas irrelevantes (`Unnamed: 0`, `Index`).
- Se filtran sÃ³lo columnas numÃ©ricas.
- Se imputan valores faltantes con la media.
- Se separan las variables predictoras (`X`) de la variable objetivo (`y`).
- Se divide el dataset en entrenamiento y prueba (70% test, estratificado).

---

### 3. **DefiniciÃ³n de Funciones**

- `run_xgb_model(...)`: entrena un modelo `XGBClassifier`, con opciÃ³n de ajustar el parÃ¡metro `scale_pos_weight` para desbalanceo.
- `show_results(...)`: genera la matriz de confusiÃ³n y mÃ©tricas de evaluaciÃ³n (`precision`, `recall`, `f1-score`).

---

### âš™ï¸ Estrategias de Balanceo Probadas

Cada bloque entrena un modelo XGBoost con una estrategia distinta de balanceo. Se evalÃºan con el mismo conjunto de prueba.

| Estrategia | DescripciÃ³n |
| --- | --- |
| ğŸ”¹ Sin balanceo | Modelo base, sin ajuste por desbalanceo. |
| ğŸ”¹ `scale_pos_weight` | Ajuste de peso para la clase minoritaria (fraude). |
| ğŸ”¹ Under-sampling | Usa `NearMiss()` para reducir la clase mayoritaria. |
| ğŸ”¹ Over-sampling | Usa `RandomOverSampler()` para duplicar muestras de la clase minoritaria. |
| ğŸ”¹ SMOTE-Tomek | CombinaciÃ³n de oversampling (SMOTE) y limpieza (Tomek links). |
| ğŸ”¹ Ensemble balanceado | Usa `BalancedBaggingClassifier` con `XGBClassifier` como modelo base. |

---

### ğŸ“Š Resultados

Cada modelo genera:

- Matriz de confusiÃ³n
- MÃ©tricas de clasificaciÃ³n (`precision`, `recall`, `f1-score`) por clase

### ğŸ“Š ComparaciÃ³n de Resultados - Modelo XGBoost

| MÃ©todo | Clase | Precision | Recall | F1-score | Accuracy |
| --- | --- | --- | --- | --- | --- |
| **1. Sin Balanceo** | Sin fraude | 0.98 | 0.99 | 0.99 |  |
|  | Con fraude | 0.98 | 0.93 | 0.95 | **0.98** |
|  | **Macro Avg** | **0.98** | 0.96 | 0.97 |  |
|  | **Weighted** | **0.98** | 0.98 | 0.98 |  |
| **2. Scale Pos Weight** | Sin fraude | 0.98 | 0.99 | 0.99 |  |
|  | Con fraude | 0.97 | 0.95 | 0.96 | **0.98** |
|  | **Macro Avg** | **0.98** | 0.97 | 0.97 |  |
|  | **Weighted** | **0.98** | 0.98 | 0.98 |  |
| **3. Under-sampling** | Sin fraude | 1.00 | 0.58 | 0.73 |  |
|  | Con fraude | 0.40 | 1.00 | 0.57 | **0.67** |
|  | **Macro Avg** | **0.70** | 0.79 | 0.65 |  |
|  | **Weighted** | **0.87** | 0.67 | 0.70 |  |
| **4. Over-sampling** | Sin fraude | 0.98 | 0.99 | 0.99 |  |
|  | Con fraude | 0.97 | 0.94 | 0.95 | **0.98** |
|  | **Macro Avg** | **0.98** | 0.97 | 0.97 |  |
|  | **Weighted** | **0.98** | 0.98 | 0.98 |  |
| **5. Ensemble Balanceado** | Sin fraude | 0.99 | 0.98 | 0.98 |  |
|  | Con fraude | 0.94 | 0.96 | 0.95 | **0.98** |
|  | **Macro Avg** | **0.96** | 0.97 | 0.97 |  |
|  | **Weighted** | **0.98** | 0.98 | 0.98 |  |

---

### ğŸ“ Observaciones clave:

- **Sin balanceo**, el modelo ya tenÃ­a un rendimiento muy alto, pero con **falsos negativos** mÃ¡s marcados (recall mÃ¡s bajo para fraudes).
- **`scale_pos_weight` y `Over-sampling`** mejoran el recall para la clase minoritaria (`Con fraude`), manteniendo la precisiÃ³n general.
- **Under-sampling** causa una gran pÃ©rdida de precisiÃ³n para la clase minoritaria, aunque logra alto recall (predice todos los fraudes, pero con muchos falsos positivos).
- **Balanced Bagging Ensemble** ofrece un muy buen equilibrio entre clases, con **mejor precision-recall para fraudes** sin sacrificar demasiado la clase mayoritaria.

### ğŸ§  ConclusiÃ³n final:

> El mÃ©todo de Balanced Bagging Ensemble es el mÃ¡s robusto y efectivo para el modelo XGBoost, ya que logra un balance Ã³ptimo entre precisiÃ³n y recall para ambas clases, lo cual es esencial en tareas sensibles como la detecciÃ³n de fraude. Ofrece alta capacidad de detecciÃ³n sin comprometer la fiabilidad general del sistema.


# ğŸ§  ComparaciÃ³n de modelos

ğŸ§¾ A lo largo del proyecto se evaluaron varios enfoques distintos para la detecciÃ³n de fraudes: un modelo de regresiÃ³n logÃ­stica, una red neuronal implementada manualmente, una red neuronal utilizando Keras, un modelo clÃ¡sico de Machine Learning basado en Random Forest y un modelo XGBoost. Cada uno de estos modelos fue probado tanto con como sin tÃ©cnicas de balanceo como oversampling (excepto el modelo de Random Forest), undersampling, etc y se analizaron sus resultados de manera integral.

ğŸ§  RegresiÃ³n logÃ­stica s**in balanceo**

Alta precisiÃ³n para la clase *sin fraude* (0.98), pero muy bajo recall para *fraude* (0.17). Tiene alta exactitud general (0.89), pero prÃ¡cticamente no detecta fraudes. Inadecuado para contextos donde el recall en la clase minoritaria es clave.

ğŸ§  RegresiÃ³n logÃ­stica con **`class_weight='balanced'`**

Mejora el recall de *fraude* (0.71), pero con baja precisiÃ³n (0.29), lo que genera muchos falsos positivos. Aumenta la sensibilidad al fraude, sacrificando exactitud global (0.73). Ãštil cuando se prioriza no perder fraudes. 

ğŸ§  RegresiÃ³n logÃ­stica con **Under-sampling (NearMiss)**

Muy alto recall en *fraude* (0.99), pero muy baja precisiÃ³n (0.29), afectando fuertemente la exactitud (0.67). Aumenta sensibilidad, pero a costa de generar muchos errores de clasificaciÃ³n. Solo recomendable si detectar fraudes a toda costa es la prioridad.

ğŸ§  RegresiÃ³n logÃ­stica con **Over-sampling (RandomOverSampler)** 

Buen balance entre precisiÃ³n y recall: 0.94 y 0.73 para *fraude* respectivamente. Accuracy global aceptable (0.92). Riesgo leve de overfitting, pero rendimiento general estable.

ğŸ§  RegresiÃ³n logÃ­stica con **Balanced Bagging**

F1-score alto en *fraude* (0.85) con buen balance entre precisiÃ³n (0.86) y recall (0.83). Accuracy alta (0.95), sin comprometer la detecciÃ³n de fraudes. Mejor opciÃ³n global: logra equilibrio sin modificar la distribuciÃ³n de test. Siendo esta variante la mejor opciÃ³n para este modelo, arrojando las mejores mÃ©tricas.

ğŸ§  **XGBoost sin balanceo**

Muy alta precisiÃ³n (0.98) y accuracy (0.98), pero recall para *fraude* algo limitado (0.93). F1-score en fraude de 0.95. Rinde muy bien, pero tiende a favorecer la clase mayoritaria.

ğŸ§  **XGBoost con `scale_pos_weight`** 

Mejora el recall en *fraude* a 0.95 manteniendo precisiÃ³n alta (0.97). F1-score en *fraude* de 0.96, accuracy total de 0.98. Excelente opciÃ³n para ajustar desequilibrio leve-moderado sin alterar los datos. 

ğŸ§  **XGBoost con Under-sampling (NearMiss)**

Recall perfecto en *fraude* (1.00), pero precisiÃ³n muy baja (0.40) y accuracy general baja (0.67). F1-score de 0.57 en fraude. Ãštil en casos donde no se puede permitir pasar un fraude, pero muy ineficiente globalmente.

ğŸ§  **XGBoost con Over-sampling (RandomOverSampler)** 

Alto rendimiento: precisiÃ³n de 0.97 y recall de 0.94 en *fraude*, F1-score de 0.95. Accuracy estable en 0.98. Buena opciÃ³n con bajo riesgo de overfitting en este caso.

ğŸ§  **XGBoost con Balanced Bagging** 

Gran equilibrio: precisiÃ³n (0.94), recall (0.96), F1-score (0.95) en *fraude*. Accuracy total muy alta (0.98). Mejor alternativa general, detecta fraudes sin afectar negativamente el rendimiento global. Siendo esta variante la mejor opciÃ³n para este modelo, arrojando las mejores mÃ©tricas.

ğŸ§  **Red neuronal implementada manualmente (sin oversampling)**

Este modelo mostrÃ³ un muy buen desempeÃ±o general. Con una accuracy del 95.7% en el conjunto de prueba, y valores altos de precisiÃ³n y recall para ambas clases (f1-score de 0.90 para la clase de fraude), demostrÃ³ una buena capacidad de generalizaciÃ³n sin indicios de sobreajuste. La diferencia mÃ­nima entre accuracy de entrenamiento (0.966) y prueba (0.957) refuerza esta observaciÃ³n. Fue el modelo con mejor desempeÃ±o dentro del enfoque de redes neuronales.

ğŸ§  **Red neuronal implementada manualmente (con SMOTE)**

Al aplicar oversampling con SMOTE, el modelo mostrÃ³ un fuerte deterioro en el rendimiento general. Aunque se logrÃ³ un recall de 0.99 para la clase de fraude (lo que indica que detectÃ³ casi todos los fraudes), esto vino acompaÃ±ado de una caÃ­da severa en el accuracy general (entre 45% y 60%) y un aumento significativo de falsos positivos. Esto sugiere que los datos sintÃ©ticos generados no representaron adecuadamente la clase minoritaria, afectando la capacidad del modelo de generalizar.

ğŸ§  **Red neuronal con Keras (sin oversampling)**

El modelo desarrollado con Keras, a pesar de tener una estructura similar al modelo implementado a mano, presentÃ³ peores resultados. Aunque el accuracy se mantuvo aceptable (87%), el desempeÃ±o sobre la clase minoritaria fue claramente inferior: el modelo solo detectÃ³ correctamente 287 de los 650 fraudes. El f1-score de la clase 1 fue de 0.59, reflejando una baja sensibilidad.

ğŸ§  **Red neuronal con Keras (con SMOTE)**

Con oversampling, el rendimiento sobre la clase minoritaria mejorÃ³ considerablemente (recall de 0.88 y f1-score de 0.70), aunque a costa de una caÃ­da en la precisiÃ³n (aumento de falsos positivos) y un descenso general en el accuracy (83%). Este escenario muestra una compensaciÃ³n favorable en tÃ©rminos de justicia con la clase minoritaria, aunque aÃºn por debajo del rendimiento de otros modelos.

ğŸ§  **Random Forest (sin oversampling)**

Los resultados obtenidos con Random Forest fueron los mÃ¡s destacados de todos los modelos probados. Se alcanzÃ³ un accuracy del 98%, con una excelente capacidad para clasificar correctamente ambas clases (f1-score de 0.96 para la clase de fraude). El modelo demostrÃ³ una robustez sorprendente sin necesidad de normalizaciÃ³n ni tÃ©cnicas de oversampling, y presentÃ³ una curva ROC con AUC â‰ˆ 1.00, lo que indica una separaciÃ³n casi perfecta entre clases.

### ğŸ“Š ComparaciÃ³n de MÃ©tricas

| MÃ©trica | Red Neuronal  | Keras | Random Forest | RegresiÃ³n logÃ­stica (**Balanced Bagging**) | XGBoost (**Balanced Bagging**) |
| --- | --- | --- | --- | --- | --- |
| Accuracy | 0.95 | 0.87 | 0.98 | 0.97 | 0.98 |
| Precision clase 0 | 0.96 | 0.86 | 0.98 | 0.98 | 0.99 |
| Recall clase 0 | 0.98 | 0.99 | 1 | 0.97 | 0.98 |
| F1-score clase 0 | 0.97 | 0.92 | 0.99 | 0.98 | 0.98 |
| Presicion clase 1 | 0.93 | 0.92 | 0.99 | 0.91 | 0.94 |
| Recall clase 1 | 0.86 | 0.44 | 0.94 | 0.94 | 0.96 |
| F1-score clase 1 | 0.89 | 0.60 | 0.96 | 0.92 | 0.95 |
| Macro avg F1-score | 0.93 | 0.76 | 0.97 | 0.95 | 0.97 |
| Weighted avg F1-score | 0.95 | 0.85 | 0.98 | 0.97 | 0.98 |

---

### ğŸ“Œ ConclusiÃ³n

Dado el desempeÃ±o superior en tÃ©rminos de precisiÃ³n, recall, f1-score y robustez general, se eligiÃ³ **Random Forest** y **XGBoost (Balanced Bagging)** como modelos fiables para el proyecto, aunque el modelo de regresiÃ³n logÃ­stica (**Balanced Bagging**) tiene muy buenas mÃ©tricas y la red neuronal tambiÃ©n es buena opciÃ³n. A diferencia de las redes neuronales, y el de regresiÃ³n logÃ­stica, Random Forest no requiriÃ³ tÃ©cnicas adicionales de balanceo ni normalizaciÃ³n (aunque al normalizar los datos, el modelo de random forest pasÃ³ de presentar un valor de 0.93 en racall para fraude a 0.94, es decir, mejorÃ³).

# ObtenciÃ³n de datos de Alchemy

### ğŸ§¾ Script de ExtracciÃ³n de Features de Transacciones Ethereum

Este script permite obtener transacciones recientes en la red Ethereum usando la API de Alchemy, identificar direcciones involucradas, recuperar sus transacciones histÃ³ricas y generar un conjunto de features Ãºtiles para anÃ¡lisis y modelos predictivos.

```jsx
scripts/extract_eth_features.py
```

### âš™ï¸ Requisitos

- Python 3.7+
- Paquetes:

```jsx
pip install requests pandas
```

### ğŸ”‘ ConfiguraciÃ³n

EditÃ¡ la variable `ALCHEMY_API_KEY` en el script con tu propia clave de API de [Alchemy](https://www.alchemy.com/).

```jsx
ALCHEMY_API_KEY = "TU_API_KEY_AQUI"
```

### ğŸ§  QuÃ© hace el script

1. Consulta las transacciones externas y ERC20 mÃ¡s recientes de la red Ethereum (Ãºltimo minuto).
2. Extrae todas las direcciones (`from` y `to`) involucradas.
3. Descarga transacciones histÃ³ricas de cada direcciÃ³n encontrada.
4. Calcula estadÃ­sticas y features relevantes como:
    - Totales y promedios de ETH enviados/recibidos
    - Tokens Ãºnicos utilizados
    - Tiempos entre transacciones
    - Token ERC20 mÃ¡s utilizado
5. Guarda los resultados como un archivo CSV.

---

### â–¶ï¸ CÃ³mo usar

```jsx
python scripts/extract_eth_features.py
```

Esto generarÃ¡ un archivo llamado `historical_features_eth.csv`, con una fila por direcciÃ³n y mÃ©tricas Ãºtiles como:

- `Avg_Value_Received`
- `Max_Val_Sent`
- `ERC20_Most_Rec_Token_Type`
- `Time_Diff_between_first_and_last(Mins)`
- ...y muchos mÃ¡s.

### ğŸ“Œ Consideraciones

- Cada direcciÃ³n se consulta individualmente, lo que puede demorar si hay muchas direcciones.
- Se incluye un `sleep(0.2)` para evitar lÃ­mites de tasa de Alchemy.
- El nÃºmero de transacciones histÃ³ricas recuperadas por address es configurable con `max_tx`.

### ğŸ› ï¸ PersonalizaciÃ³n

Se puede modificar:

- El perÃ­odo reciente de transacciones (`minutes=1`)
- La cantidad de transacciones histÃ³ricas por direcciÃ³n (`max_tx=100`)
- Los features calculados en la funciÃ³n `extract_features`

### CreaciÃ³n de datos para probar con los distintos modelos

El dataset limpio con el que estamos ejecutando el modelo (`transaction_dataset_clean.csv`) tiene las siguientes columnas:

- Avg min between sent tnx
- Avg min between received tnx
- Time Diff between first and last (Mins)
- Sent tnx
- Received Tnx
- Number of Created Contracts
- Unique Received From Addresses
- Unique Sent To Addresses
- min value received
- max value received
- avg val received
- min val sent
- max val sent
- avg val sent
- min value sent to contract
- avg value sent to contract
- total transactions (including tnx to create contract)
- total Ether sent
- total ether received
- total ether sent contracts
- total ether balance
- Total ERC20 tnxs
- ERC20 total Ether sent contract
- ERC20 uniq sent addr
- ERC20 uniq rec addr
- ERC20 uniq sent addr.1
- ERC20 uniq rec contract addr
- ERC20 min val rec
- ERC20 max val rec
- ERC20 avg val rec'
- ERC20 avg val sent
- ERC20 uniq sent token name

# ğŸ“Š Resultados dataset externo

Se trabajÃ³ con un **dataset externo (obtenido de la pÃ¡gina de Alchemy) compuesto por 580 muestras** para determinar si alguna de las transacciones resultÃ³ fraudolenta, de acuerdo a los modelos desarrollados en el proyecto: un **Random Forest**, una **Red Neuronal con Keras** y una **Red Neuronal implementada manualmente,** una **RegresiÃ³n logÃ­stica** y un **XGBoost**. A continuaciÃ³n se detallan los resultados obtenidos con cada modelo y un anÃ¡lisis comparativo.

---

### ğŸŒ² Modelo 1: Random Forest

- **Resumen de resultados:**
    - MÃ¡s de **300 muestras** arrojaron una probabilidad de fraude de aproximadamente **27%**.
    - Cerca de **150 muestras** se ubicaron alrededor del **39%** de probabilidad.
    - Las restantes muestras se distribuyeron entre **0% y 43%**, siendo muy pocas.
    
    ![Probabilidad con Random Forest](img/rf.png)
    
- **AnÃ¡lisis:**
    - Este modelo **no muestra una evidencia clara** de fraude en las transacciones evaluadas.
    - Las probabilidades se mantienen en un rango medio sin alcanzar valores extremos.
    - A pesar de la distribuciÃ³n, **este fue uno de los modelos con mejores mÃ©tricas**, cercanas a la perfecciÃ³n.
- **ConclusiÃ³n parcial:**
    
    > Si bien el modelo detecta ciertos patrones, no hay elementos concluyentes para afirmar que existan transacciones fraudulentas. Su alta precisiÃ³n refuerza la idea de una clasificaciÃ³n conservadora pero confiable.
    > 

---

### ğŸ¤– Modelo 2: Red Neuronal con Keras

- **Resumen de resultados:**
    - Aproximadamente **400 muestras** dieron menos del **10%** de probabilidad de fraude.
    - MÃ¡s de **150 muestras** se ubicaron entre el **40% y 45%**.
    - Algunas muestras incluso superaron el **90%** de probabilidad.

![Probabilidad con keras](img/keras.png)

- **AnÃ¡lisis:**
    - A pesar de detectar algunas transacciones con alta probabilidad, **las mÃ©tricas generales del modelo fueron malas**.
    - El modelo **carece de confiabilidad** para identificar fraudes con certeza.
    - Es probable que estÃ© reaccionando de forma espuria a patrones que no son relevantes.
- **ConclusiÃ³n parcial:**
    
    > No se recomienda utilizar este modelo como referencia para detectar fraude, ya que sus resultados no estÃ¡n respaldados por un desempeÃ±o sÃ³lido en mÃ©tricas.
    > 

---

### ğŸ§  Modelo 3: Red Neuronal Manual

- **Resumen de resultados:**
    - MÃ¡s de **400 muestras** colapsan cerca de **0** (no fraude).
    - **146 muestras** se ubican por encima del **75%**, cercanas a **1** (fraude).

![Probabilidad con Red Neuronal](img/red.png)

- **AnÃ¡lisis:**
    - Este modelo fue diseÃ±ado para colapsar hacia extremos (0 o 1), logrando una **discriminaciÃ³n clara** entre clases.
    - PresentÃ³ **muy buenas mÃ©tricas** (aunque inferiores al Random Forest, RegresiÃ³n LogÃ­stica y XGBoost).
    - El resultado refleja una distribuciÃ³n **coherente con la del dataset original**, donde aproximadamente el **22% eran fraudes**. En este caso cerca del 25% de las transacciones serÃ­an fraudolentas.
- **ConclusiÃ³n parcial:**
    
    > El modelo representa de forma realista la proporciÃ³n esperada de fraudes, mostrando un comportamiento robusto ante el dataset externo, aunque no es tan preciso como los modelos de Random Forest, RegresiÃ³n LogÃ­stica y XGBoost.
    > 

---

### ğŸ“ˆ Modelo 4: RegresiÃ³n LogÃ­stica (Balanced Bagging)

- **Resumen de resultados:**
    - 566 muestras tuvieron una probabilidad de fraude menor al 10%.
    - Pocas muestras tuvieron una probabilidad mayor al 50%, solo 8 muestras con una probabilidad del 80%.

![Probabilidad con RegresiÃ³n logÃ­stica](img/regresiÃ³n.png)

- **AnÃ¡lisis:**
    - PresentÃ³ **muy buenas mÃ©tricas** (aunque levemente inferiores al Random Forest y XGBoost).
    - **DistribuciÃ³n**: Extremadamente similar a la de **XGBoost**, con una gran acumulaciÃ³n en zona no fraude.
- **ConclusiÃ³n parcial:**
    
    > **Modelo confiable en mÃ©tricas**, y muy prudente en nuevas predicciones. Junto a XGBoost, revela un patrÃ³n comÃºn de detecciÃ³n extremadamente conservadora.
    > 

---

### âš¡  Modelo 5: XGBoost (Balanced Bagging)

- **Resumen de resultados:**
    - 566 muestras tuvieron una probabilidad de fraude menor al 10%.
    - Pocas muestras tuvieron una probabilidad mayor al 50%, solo 4 muestras con una probabilidad mayor al 78% y una de ellas alcanza el 90%.

![Probabilidad con XGBoost](img/XGBoost.png)

- **AnÃ¡lisis:**
    - Junto con Random Forest presentÃ³ las mejores mÃ©tricas.
    - **DistribuciÃ³n**: Extremadamente similar a la de RegresiÃ³n LogÃ­stica, con una gran acumulaciÃ³n en zona no fraude.
- **ConclusiÃ³n parcial:**
    
    > **Modelo muy confiable**. A pesar de su bajo nÃºmero de predicciones de fraude, lo hace con alta seguridad. Su distribuciÃ³n refleja un comportamiento predecible y sÃ³lido, en lÃ­nea con RegresiÃ³n LogÃ­stica.
    > 

### ğŸ“Œ ConclusiÃ³n General

- El modelo de **Random Forest** se destacÃ³ por sus **mÃ©tricas muy buenas**, y aunque no ofreciÃ³ predicciones extremas, su resultado sugiere **una clasificaciÃ³n confiable** sin falsos positivos notables, aunque tiene **cierta indecisiÃ³n al clasificar**.
- La **Red con Keras** mostrÃ³ ser poco Ãºtil para el problema en cuestiÃ³n debido a su bajo rendimiento general, a pesar de algunas predicciones alarmantes.
- La **Red Manual** se comportÃ³ de forma **coherente con la distribuciÃ³n real de clases (conforme al dataset del cual se entrenaron los modelos)**, indicando una capacidad de generalizaciÃ³n sÃ³lida frente al nuevo dataset.
- **XGBoost y RegresiÃ³n LogÃ­stica**: Aunque conservadores, son consistentes entre sÃ­, ademÃ¡s de presentar **muy buenas mÃ©tricas** (sobre todo **XGBoost**). Su similitud en la distribuciÃ³n refuerza la validez de sus predicciones.

# ğŸ“„ Streamlit

---

## ğŸ”¹ DescripciÃ³n general

La aplicaciÃ³n fue desarrollada en Python usando **Streamlit** para construir una interfaz web interactiva que permite detectar transacciones fraudulentas en la red Ethereum.

Emplea **mÃºltiples modelos de machine y deep learning previamente entrenados y serializados** para emitir una predicciÃ³n confiable y explicable. La consulta de datos se realiza a travÃ©s de la API de **Alchemy**, y los resultados se presentan con visualizaciones claras e informes descargables.

---

## ğŸ”¹ Objetivo

Permitir al usuario cargar una transacciÃ³n especÃ­fica (por su `hash`) o consultar un conjunto reciente de transacciones, y obtener un diagnÃ³stico automÃ¡tico sobre si es **fraude o no**, respaldado por:

- Predicciones de varios modelos.
- GrÃ¡ficos de probabilidad.
- EstadÃ­sticas clave.
- Un informe descargable con lo anterior mencionado.

---

## ğŸ”¹ Modelos utilizados

Se utilizan **cinco modelos** de machine learning y deep learning previamente entrenados sobre un dataset etiquetado. 

- ğŸ§  **Red neuronal manual (con propagaciÃ³n hacia adelante)**
- ğŸ¤– **Red Kera**
- ğŸŒ² **Random Forest**
- ğŸ“ˆ **RegresiÃ³n logÃ­stica con Balanced Bagging**
- âš¡ **XGBoost con Balanced Bagging**

Cada modelo predice una probabilidad de que la transacciÃ³n sea fraudulenta.

ğŸ“¦ **Carga de modelos**

En el backend, se utiliza cÃ³digo como este:

### **`cargar_modelo(nombre_modelo)`**

```python

def cargar_modelo(nombre_modelo):
    return joblib.load(f'../models/{nombre_modelo}')
```

- Carga los modelos previamente entrenados desde el directorio `../models/`.

---

## ğŸ”¹ Flujo de uso

### ğŸŸ¢ Ingreso de datos

El usuario puede:

1. Ingresar un `hash` de transacciÃ³n de Ethereum.
2. Consultar un conjunto histÃ³rico de transacciones configurando:
    - â±ï¸ Tiempo hacia atrÃ¡s (en minutos).
    - ğŸ“Š Cantidad mÃ¡xima de transacciones.

### ğŸ” Consulta de datos (Alchemy)

Se consulta la API de **Alchemy** para obtener las caracterÃ­sticas de la transacciÃ³n o del conjunto.

Se usa una funciÃ³n como esta para obtener los datos

```python
load_dotenv(dotenv_path=os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), ".env"))
api_key = os.getenv("ALCHEMY_API_KEY")
if not api_key:
    raise ValueError("âš ï¸ API_KEY no estÃ¡ definida en las variables de entorno")
ALCHEMY_URL = f"https://eth-mainnet.g.alchemy.com/v2/{api_key}"
```

Se usa una funciÃ³n como esta para obtener los datos:

---

### ğŸ§  PredicciÃ³n mÃºltiple

Cada modelo recibe los mismos datos y devuelve una probabilidad de fraude (entre 0 y 1).

### **`predecir_modelo(...)`**

```python
python
CopiarEditar
def predecir_modelo(modelo, X, nombre_modelo, scaler=None):
    ...
```

Esta es la funciÃ³n mÃ¡s importante y se adapta segÃºn el tipo de modelo.

### **ParÃ¡metros:**

- `modelo`: el modelo cargado (Keras, red neuronal manual, XGBoost, etc.).
- `X`: los datos de entrada para predecir.
- `nombre_modelo`: string que indica quÃ© tipo de modelo es.
- `scaler`: objeto de escalado (puede ser `None`).

### **LÃ³gica:**

1. Aplica el scaler si existe.
2. SegÃºn el tipo de modelo (`nombre_modelo`), predice probabilidades y clases:
    - **Keras**:
        - Usa `.predict`.
        - Usa `argmax` para clase y `[:, 1]` para probabilidad de fraude.
    - **Red neuronal manual**:
        - Usa matrices `W1`, `b1`, `W2`, `b2`, y funciones `FunH`, `FunO`.
        - Calcula **propagaciÃ³n hacia adelante** manualmente.
        - Usa `evaluar(Fun, neta)` para aplicar funciones de activaciÃ³n.
        - Imprime diagnÃ³stico de predicciones.
    - **XGBoost**:
        - Usa `predict_proba` y decide clase con umbral 0.5.
        - TambiÃ©n imprime info diagnÃ³stica.
    - **Otros modelos (Random Forest, Logistic, etc.)**:
        - Usa `predict` y `predict_proba` de `sklearn`.

### **Devuelve:**

```python
return y_pred, y_pred_proba, tiempo_ejecucion
```

- `y_pred`: clase predicha (0 = no fraude, 1 = fraude).
- `y_pred_proba`: probabilidad de fraude.
- `tiempo_ejecucion`: cuÃ¡nto tardÃ³ la predicciÃ³n.

---

### âš–ï¸ DecisiÃ³n final

Si **2 o mÃ¡s modelos** predicen una probabilidad > 0.75, se considera que la transacciÃ³n es fraudulenta.

```python
CopiarEditar
if sum(prob > 0.75 for prob in probabilidades_modelos) >= 2:
    resultado = "âŒ Fraude"
else:
    resultado = "âœ… No fraude"
```

---

### ğŸ“º VisualizaciÃ³n del resultado

En la interfaz se muestra:

- Etiqueta final: "âœ… No fraude" o "âŒ Fraude"

---

## ğŸ“„ Informe descargable

El usuario puede generar un informe PDF que incluye:

- Histograma de probabilidades por modelo
- MÃ©tricas de cada modelo (F1-score, precisiÃ³n, recall, etc.)
- Fecha de consulta y hash analizado

---

## ğŸ§  Ventajas del enfoque

- âœ… **Multimodelo**: robustez frente a errores individuales
- âœ… **Explicabilidad**: visualizaciones claras e informes detallados
- âœ… **Simplicidad**: basta con un `hash` o un parÃ¡metro de tiempo para una serie de transacciones
- âœ… **Modularidad**: fÃ¡cil de extender con mÃ¡s modelos o mejoras en la interfaz


# âœ… Conclusiones Finales

El presente proyecto logrÃ³ desarrollar un sistema efectivo para la **detecciÃ³n automÃ¡tica de transacciones fraudulentas en la red de Ethereum**, combinando tÃ©cnicas clÃ¡sicas y modernas de aprendizaje automÃ¡tico. A travÃ©s del anÃ¡lisis, preprocesamiento y modelado de datos histÃ³ricos, se construyÃ³ una base sÃ³lida para abordar un problema real con alto impacto en la comunidad cripto.

A lo largo del proceso se cumpliÃ³ con cada uno de los objetivos propuestos:

- Se realizÃ³ un **anÃ¡lisis exploratorio exhaustivo** que permitiÃ³ entender mejor el comportamiento de las transacciones y preparar adecuadamente el dataset.
- Se entrenaron y compararon **cinco modelos de clasificaciÃ³n**, incluyendo algoritmos clÃ¡sicos como RegresiÃ³n LogÃ­stica y Random Forest, asÃ­ como modelos de redes neuronales profundas.
- La evaluaciÃ³n de los modelos se llevÃ³ a cabo mediante mÃ©tricas como accuracy, precisiÃ³n, recall y F1-score, permitiendo una **comparaciÃ³n objetiva del rendimiento**.
- La mayorÃ­a de los modelos se destacaron como robustos y confiables, tanto en el conjunto de validaciÃ³n como frente a nuevos datos externos.
- Se implementÃ³ un sistema de consulta en **tiempo real a travÃ©s de la API de Alchemy**, integrando estos datos al pipeline de predicciÃ³n tras una estandarizaciÃ³n adecuada.
- Finalmente, se desarrollÃ³ una **aplicaciÃ³n web con Streamlit**, que permite a los usuarios finales consultar cualquier transacciÃ³n y predecir su legitimidad de forma accesible e interactiva.

El sistema resultante constituye una **herramienta prÃ¡ctica, modular y reutilizable**, adaptable a futuras mejoras tanto en el volumen de datos como en la arquitectura de los modelos. AdemÃ¡s, al estar disponible en GitHub, el proyecto fomenta la **colaboraciÃ³n abierta y el uso responsable de la inteligencia artificial en entornos financieros**.

Este trabajo no solo demuestra la viabilidad de aplicar machine learning al monitoreo de redes blockchain, sino que tambiÃ©n sienta las bases para **mejoras futuras en la prevenciÃ³n de fraudes**, con la posibilidad de incorporar tÃ©cnicas mÃ¡s avanzadas como detecciÃ³n de anomalÃ­as, aprendizaje semi-supervisado o integraciÃ³n de modelos de grafos.