import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import time
import glob
import os
import sys
import subprocess
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Agregar directorios de funciones al path
project_root = os.path.abspath(os.path.dirname(__file__))
sys.path.append(os.path.join(project_root, 'common_functions'))
sys.path.append(os.path.join(project_root, 'scripts', 'get_data'))
sys.path.append(os.path.join(project_root, 'scripts', 'model_evaluation'))

# Importar funciones del script original
from scripts.model_evaluation.evaluate_models import (
    cargar_modelo,
    cargar_scaler,
    asegurar_columnas,
    predecir_modelo
)

# Importar funciones para descarga de datos
from scripts.get_data.generate_eth_features_history import (
    get_recent_transfers as get_recent_transactions,
    get_transaction_by_hash as get_transaction_data,
    extract_features as generate_features,
    get_historical_transfers_for_address
)

def cargar_dataset_mas_reciente():
    """Carga el dataset m谩s reciente o genera uno nuevo si no existe"""
    features_dir = os.path.join(project_root, "features_downloads")
    initial_file = os.path.join(features_dir, "features_recent_*_*.csv")
    archivos = glob.glob(initial_file)
    if not archivos:
        try:
            st.warning("No se encontraron datos recientes. Generando nuevo dataset...")
            # Configuraci贸n por defecto para generar nuevos datos
            minutes = 1  # 煤ltimo minuto
            max_tx = 5  # m谩ximo 10 transacciones            
            get_data_path = os.path.join(project_root, "scripts", "get_data")
            comando = [sys.executable, "generate_eth_features_history.py", 
                                                "--minutes", str(minutes), 
                                                "--max_tx", str(max_tx)]
            os.chdir(get_data_path) # nos movemos al directorio get_data para ejecutar el comando
            process = subprocess.Popen(
                comando,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                encoding="utf-8" # <- Esto fuerza la decodificaci贸n como UTF-8
            )
            output_placeholder = st.empty()
            for line in process.stdout:
                output_placeholder.info(line.strip()) # Solo muestra la 煤ltima l铆nea
            process.wait()
            os.chdir(project_root) # volvemos a la raiz del proyecto

            if process.returncode == 0:
                st.success("Script ejecutado correctamente.")
            else:
                st.error("Error al generar nuevos datos")
                return None 
        except Exception as e:
            st.error(f'No se pudo ejecutar el script de generaci贸n de nuevos datos: {e}')
            return None
    # Buscar el archivo generado
    archivos = glob.glob(initial_file)
    if not archivos:
        st.error("No se gener贸 el archivo de features")
        return None
    archivo_mas_reciente = max(archivos, key=os.path.getmtime)
    st.info(f"Dataset cargado: {archivo_mas_reciente}")
    return pd.read_csv(archivo_mas_reciente)

def mostrar_metricas(y_true, y_pred, y_prob):
    """Muestra las m茅tricas de evaluaci贸n"""
    metricas = {
        'Accuracy': accuracy_score(y_true, y_pred),
        'Precision': precision_score(y_true, y_pred),
        'Recall': recall_score(y_true, y_pred),
        'F1-Score': f1_score(y_true, y_pred),
        'ROC-AUC': roc_auc_score(y_true, y_prob)
    }
    
    # Crear DataFrame con m茅tricas
    df_metricas = pd.DataFrame({
        'M茅trica': list(metricas.keys()),
        'Valor': [f"{v:.3f}" for v in metricas.values()]
    })
    
    return df_metricas

def descargar_datos_recientes(minutes, max_tx):
    """Descarga datos de transacciones recientes y su hist贸rico"""
    with st.spinner("Descargando transacciones recientes..."):
        try:
            # Obtener transacciones recientes
            recent_tx = get_recent_transactions(minutes=minutes, max_tx=max_tx)
            if not recent_tx:
                st.error("No se encontraron transacciones recientes")
                return None
            
            st.info(f"Se obtuvieron {len(recent_tx)} transacciones recientes")
            
            # Obtener direcciones 煤nicas de remitentes
            addresses = set()
            for tx in recent_tx:
                if tx.get("from"):
                    addresses.add(tx["from"])
            
            st.info(f"Consultando hist贸rico para {len(addresses)} direcciones...")
            
            # Obtener hist贸rico para cada direcci贸n
            all_hist_txs = recent_tx.copy()
            for i, addr in enumerate(addresses):
                st.text(f"Consultando hist贸rico para {addr} ({i+1}/{len(addresses)})")
                hist_txs = get_historical_transfers_for_address(addr, max_tx=max_tx)
                all_hist_txs.extend(hist_txs)
                time.sleep(0.25)  # Evitar rate limiting
            
            st.info(f"Total de transacciones hist贸ricas recopiladas: {len(all_hist_txs)}")
            
            # Generar features
            st.text("Extrayendo features...")
            features = generate_features(all_hist_txs, recent_tx)
              # Guardar resultados
            timestamp = time.strftime("%Y_%m_%d_%H_%M")
            filename = f"features_recent_{minutes}m_{max_tx}tx_{timestamp}.csv"
            file_path = os.path.join(project_root, "features_downloads", filename)
            features.to_csv(file_path, index=False)
            
            st.success(f"Datos guardados en: {filename}")
            return features
            
        except Exception as e:
            st.error(f"Error al descargar datos: {str(e)}")
            return None

def descargar_por_hash(tx_hash):
    """Descarga datos de una transacci贸n espec铆fica"""
    with st.spinner("Descargando datos de la transacci贸n..."):
        try:
            # Obtener datos de la transacci贸n
            tx_data = get_transaction_data(tx_hash)
            if not tx_data:
                st.error("No se encontr贸 la transacci贸n")
                return None
            
            # Generar features
            features = generate_features([tx_data])
              # Guardar resultados
            timestamp = time.strftime("%Y_%m_%d_%H_%M")
            filename = f"features_tx_{tx_hash[:8]}_{timestamp}.csv"
            file_path = os.path.join(project_root, "features_downloads", filename)
            features.to_csv(file_path, index=False)
            
            st.success(f"Datos guardados en: {filename}")
            return features
            
        except Exception as e:
            st.error(f"Error al descargar datos: {str(e)}")
            return None

def main():
    st.title("Evaluaci贸n de Modelos de Detecci贸n de Fraude")
    
    # Pesta帽as para diferentes funcionalidades
    tab1, tab2, tab3 = st.tabs(["Evaluaci贸n de Modelos", "Descarga de Datos", "Evaluaci贸n Conjunta"])
    
    with tab1:
        # C贸digo existente para evaluaci贸n de modelos individuales
        df = cargar_dataset_mas_reciente()
        if df is None:
            return
        
        # Guardar tx_hash antes de procesar el DataFrame
        tx_hashes = df['tx_hash'].copy() if 'tx_hash' in df.columns else None
        
        try:
            df = asegurar_columnas(df)
        except ValueError as e:
            st.error(str(e))
            return
        
        st.subheader("Selecci贸n de Modelo")
        modelo_seleccionado = st.selectbox(
            "Seleccione el modelo a evaluar:",
            ['random_forest', 'keras', 'logistic_regression', 'red_neuronal', 'xgboost']
        )
        
        try:
            modelo = cargar_modelo(f'{modelo_seleccionado}_model.joblib')
            scaler = cargar_scaler(f'{modelo_seleccionado}_scaler.joblib') if modelo_seleccionado != 'logistic_regression' else None
        except Exception as e:
            st.error(f"Error al cargar el modelo: {str(e)}")
            return
        
        if st.button("Evaluar Modelo"):
            with st.spinner("Realizando predicciones..."):
                y_pred, y_prob, tiempo = predecir_modelo(modelo, df, modelo_seleccionado, scaler)
                
                st.subheader("Resultados de la Evaluaci贸n")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Tiempo de ejecuci贸n", f"{tiempo:.3f} segundos")
                with col2:
                    st.metric("Fraudes detectados", sum(y_pred))
                with col3:
                    st.metric("Porcentaje de fraudes", f"{(sum(y_pred)/len(df)*100):.2f}%")
                
                st.subheader("Distribuci贸n de Probabilidades")
                fig, ax = plt.subplots(figsize=(10, 6))
                
                # Determinar el rango de visualizaci贸n seg煤n el modelo
                if modelo_seleccionado in ['keras', 'red_neuronal']:
                    # Modelos que usan tanh, rango [-1, 1]
                    y_prob_plot = y_prob
                    xlim_min, xlim_max = -1.05, 1.05
                    xlabel = 'Valor de Salida (tanh)'
                    umbral = 0
                    # Ajustar n煤mero de bins seg煤n el rango de valores
                    rango = y_prob_plot.max() - y_prob_plot.min()
                    n_bins = min(30, max(15, int(len(y_prob_plot) / 8)))  # Reducir n煤mero de bins para barras m谩s anchas
                    alpha = 0.6  # Mayor transparencia para mejor visualizaci贸n de superposici贸n
                else:
                    # Otros modelos usan probabilidades [0, 1]
                    y_prob_plot = y_prob
                    xlim_min, xlim_max = -0.05, 1.05
                    xlabel = 'Probabilidad de Fraude'
                    umbral = 0.5
                    n_bins = 40
                    alpha = 0.5
                
                # Crear histograma con bins ajustados y mayor ancho de barras
                ax.hist(y_prob_plot[y_pred == 0], bins=n_bins, alpha=alpha, label='No Fraude', color='green', 
                       width=(xlim_max-xlim_min)/n_bins*0.6)  # Reducir ancho de barras a 60% del espacio
                ax.hist(y_prob_plot[y_pred == 1], bins=n_bins, alpha=alpha, label='Fraude', color='red',
                       width=(xlim_max-xlim_min)/n_bins*0.6)  # Reducir ancho de barras a 60% del espacio
                
                ax.set_title(f'Distribuci贸n de Salidas - {modelo_seleccionado.replace("_", " ").title()}')
                ax.set_xlabel(xlabel)
                ax.set_ylabel('Frecuencia')
                ax.legend()
                ax.grid(True, alpha=0.3)
                ax.set_xlim(xlim_min, xlim_max)
                
                # Agregar l铆nea vertical en el umbral de decisi贸n
                ax.axvline(x=umbral, color='black', linestyle='--', alpha=0.5, label=f'Umbral ({umbral})')
                ax.legend()
                
                st.pyplot(fig)
                
                st.subheader("Informaci贸n Detallada")
                st.write(f"Rango de valores: [{y_prob_plot.min():.3f}, {y_prob_plot.max():.3f}]")
                st.write(f"Media: {y_prob_plot.mean():.3f}")
                st.write(f"Desviaci贸n est谩ndar: {y_prob_plot.std():.3f}")
                
                # Agregar informaci贸n adicional para diagn贸stico
                if modelo_seleccionado in ['keras', 'red_neuronal']:
                    st.write("Distribuci贸n de valores:")
                    st.write(f"- Valores < 0: {sum(y_prob_plot < 0)} ({sum(y_prob_plot < 0)/len(y_prob_plot)*100:.1f}%)")
                    st.write(f"- Valores = 0: {sum(y_prob_plot == 0)} ({sum(y_prob_plot == 0)/len(y_prob_plot)*100:.1f}%)")
                    st.write(f"- Valores > 0: {sum(y_prob_plot > 0)} ({sum(y_prob_plot > 0)/len(y_prob_plot)*100:.1f}%)")
                    st.write(f"N煤mero de bins en el histograma: {n_bins}")

            if st.button("Guardar Resultados"):
                dir_resultados = os.path.join(project_root, 'resultados', f'evaluacion_{modelo_seleccionado}')

                output_placeholder.info(dir_resultados)

                os.makedirs(dir_resultados, exist_ok=True)
                
                df_resultados = pd.DataFrame({
                    'prediccion': y_pred,
                    'probabilidad': y_prob
                })
                df_resultados.to_csv(os.path.join(dir_resultados, 'predicciones.csv'), index=False)
                
                fig.savefig(os.path.join(dir_resultados, 'distribucion_probabilidades.png'), dpi=300, bbox_inches='tight')
                
                st.success(f"Resultados guardados en: {dir_resultados}")
    
    with tab2:
        st.subheader("Descarga de Datos")
        
        # Opciones de descarga
        opcion_descarga = st.radio(
            "Seleccione el tipo de descarga:",
            ["Transacciones Recientes", "Transacci贸n por Hash"]
        )
        
        if opcion_descarga == "Transacciones Recientes":
            minutes = st.slider("Minutos hacia atr谩s", 1, 60, 5)
            max_tx = st.slider("N煤mero m谩ximo de transacciones", 10, 1000, 100)
            
            if st.button("Descargar Transacciones Recientes"):
                df = descargar_datos_recientes(minutes, max_tx)
                if df is not None:
                    st.dataframe(df)
        
        else:  # Transacci贸n por Hash
            tx_hash = st.text_input("Ingrese el hash de la transacci贸n:")
            
            if st.button("Descargar Datos de Transacci贸n"):
                if tx_hash:
                    df = descargar_por_hash(tx_hash)
                    if df is not None:
                        st.dataframe(df)
                else:
                    st.warning("Por favor, ingrese un hash de transacci贸n v谩lido")

    with tab3:
        st.subheader("Evaluaci贸n Conjunta de Modelos")
        
        # Cargar dataset
        df = cargar_dataset_mas_reciente()
        if df is None:
            return
        
        # Guardar tx_hash antes de procesar el DataFrame
        tx_hashes = df['tx_hash'].copy() if 'tx_hash' in df.columns else None
        
        try:
            df = asegurar_columnas(df)
        except ValueError as e:
            st.error(str(e))
            return
        
        # Inicializar variables en session_state si no existen
        if 'resultados_evaluacion' not in st.session_state:
            st.session_state.resultados_evaluacion = None
            st.session_state.df_detalles = None
            st.session_state.df_final = None
        
        # Lista de modelos a evaluar (movida fuera del bloque if)
        modelos = ['random_forest', 'keras', 'logistic_regression', 'red_neuronal', 'xgboost']
        
        if st.button("Evaluar con Todos los Modelos"):
            with st.spinner("Realizando predicciones con todos los modelos..."):
                # Diccionario para almacenar resultados
                resultados = {}
                st.session_state.df_final = df.copy()
                
                # Realizar predicciones con cada modelo
                for nombre_modelo in modelos:
                    try:
                        modelo = cargar_modelo(f'{nombre_modelo}_model.joblib')
                        scaler = cargar_scaler(f'{nombre_modelo}_scaler.joblib') if nombre_modelo != 'logistic_regression' else None
                        
                        y_pred, y_prob, tiempo = predecir_modelo(modelo, df, nombre_modelo, scaler)
                        
                        resultados[nombre_modelo] = {
                            'predicciones': y_pred,
                            'probabilidades': y_prob,
                            'tiempo': tiempo
                        }
                        
                        # Agregar predicciones al DataFrame final
                        st.session_state.df_final[f'pred_{nombre_modelo}'] = y_pred
                        st.session_state.df_final[f'prob_{nombre_modelo}'] = y_prob
                        
                    except Exception as e:
                        st.error(f"Error con el modelo {nombre_modelo}: {str(e)}")
                        return
                
                # Calcular votaci贸n (fraude si al menos 3 modelos lo detectan)
                votos = sum(st.session_state.df_final[f'pred_{modelo}'] for modelo in modelos)
                st.session_state.df_final['voto_mayoria'] = (votos >= 3).astype(int)
                
                # Crear DataFrame con las columnas solicitadas
                df_detalles = pd.DataFrame()
                
                # Agregar columna de transacci贸n
                if tx_hashes is not None:
                    # Mostrar solo los primeros 8 caracteres del hash
                    df_detalles['Transacci贸n'] = tx_hashes.str[:8] + "..."
                else:
                    df_detalles['Transacci贸n'] = [f'TX_{i+1}' for i in range(len(st.session_state.df_final))]
                
                # Agregar columnas de predicciones de cada modelo
                for modelo in modelos:
                    df_detalles[f'{modelo.replace("_", " ").title()}'] = st.session_state.df_final[f'pred_{modelo}'].map({1: '', 0: ''})
                
                # Agregar columna de predicci贸n final
                df_detalles['Predicci贸n Final'] = st.session_state.df_final['voto_mayoria'].map({1: 'Fraude', 0: 'No Fraude'})
                
                # Guardar resultados en session_state
                st.session_state.resultados_evaluacion = resultados
                st.session_state.df_detalles = df_detalles
        
        # Mostrar resultados si existen
        if st.session_state.df_detalles is not None:
            # Mostrar resumen
            st.subheader("Resumen de Predicciones")
            
            # Crear DataFrame con resumen
            resumen = pd.DataFrame({
                'Modelo': modelos,
                'Tiempo (s)': [st.session_state.resultados_evaluacion[m]['tiempo'] for m in modelos],
                'Fraudes Detectados': [sum(st.session_state.resultados_evaluacion[m]['predicciones']) for m in modelos],
                'Porcentaje de Fraudes': [f"{(sum(st.session_state.resultados_evaluacion[m]['predicciones'])/len(df)*100):.2f}%" for m in modelos]
            })
            
            st.dataframe(resumen)
            
            # Mostrar resultados de votaci贸n
            st.subheader("Resultados de Votaci贸n")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total de Transacciones", len(st.session_state.df_detalles))
            with col2:
                st.metric("Fraudes Detectados", sum(st.session_state.df_detalles['Predicci贸n Final'] == 'Fraude'))
            with col3:
                st.metric("Porcentaje de Fraudes", f"{(sum(st.session_state.df_detalles['Predicci贸n Final'] == 'Fraude')/len(st.session_state.df_detalles)*100):.2f}%")
            
            # Mostrar distribuci贸n de votos
            st.subheader("Distribuci贸n de Votos")
            fig, ax = plt.subplots(figsize=(10, 6))
            votos = sum(st.session_state.df_final[f'pred_{modelo}'] for modelo in modelos)
            ax.hist(votos, bins=6, range=(-0.5, 5.5), alpha=0.7)
            ax.set_xlabel('N煤mero de Modelos que Detectan Fraude')
            ax.set_ylabel('N煤mero de Transacciones')
            ax.set_xticks(range(6))
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            
            # Mostrar tabla de predicciones
            st.subheader("Tabla de Predicciones por Transacci贸n")
            st.dataframe(
                st.session_state.df_detalles.style.applymap(
                    lambda x: 'background-color: #ffcdd2' if x == 'Fraude' else 'background-color: #c8e6c9',
                    subset=['Predicci贸n Final']
                ),
                use_container_width=True,  # Hace que la tabla use todo el ancho disponible
                column_config={
                    "Transacci贸n": st.column_config.TextColumn(
                        "Transacci贸n",
                        width="small",
                        help="Primeros 8 caracteres del hash de la transacci贸n"
                    )
                }
            )
            
            # Bot贸n de descarga
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            csv = st.session_state.df_detalles.to_csv(index=False)
            st.download_button(
                label="Descargar Resultados",
                data=csv,
                file_name=f'predicciones_votacion_{timestamp}.csv',
                mime='text/csv',
            )

if __name__ == "__main__":
    main() 